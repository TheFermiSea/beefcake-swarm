{"id":"beefcake-swarm-0l5","title":"Make WorkPacket constraints configurable","description":"WorkPacketGenerator has hardcoded default constraints (line 46: 'No new dependencies without explicit approval', 'Don't break existing public API'). These are baked into the binary and cannot be overridden per-task.\n\nThis is problematic for tasks that intentionally require adding dependencies, changing public API, or have different LOC limits.\n\nFix: Move default constraints into SwarmConfig (or a new PackerConfig). Allow per-issue constraint overrides via beads issue labels or metadata. The ContextPacker should accept optional extra constraints that merge with (or replace) the defaults.\n\nConsider: constraints could come from beads issue fields, a .beefcake.toml project config, or CLI flags.\n\nFiles: coordination/src/work_packet/generator.rs, crates/swarm-agents/src/config.rs, coordination/src/context_packer/packer.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:20.875919-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:20.875919-06:00"}
{"id":"beefcake-swarm-2fd","title":"Add integration test for orchestrator loop","description":"There is no test that validates the full orchestrator loop data flow: ContextPacker -\u003e format_work_packet -\u003e Implementer -\u003e apply_changes -\u003e Verifier -\u003e Validator. Each component is tested in isolation but the wiring between them is only exercised by running the real binary against a live inference server.\n\nFix: Create a test in crates/swarm-agents/tests/ that:\n1. Uses mock Implementer (returns a fixed code change)\n2. Uses mock Validator (returns PASS)\n3. Sets up a real temp git repo with a known-broken Rust file\n4. Runs the loop for 1 iteration\n5. Verifies: pack_initial called, implementer received formatted prompt, verifier ran, validator received diff, issue closed\n\nThis depends on extracting agent traits (beefcake-swarm-AGENT_TRAITS_ID) so mocks can be injected.\n\nFiles: crates/swarm-agents/tests/ (new), crates/swarm-agents/src/main.rs\nDepends on: agent traits extraction\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:35.314013-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:35.314013-06:00","dependencies":[{"issue_id":"beefcake-swarm-2fd","depends_on_id":"beefcake-swarm-7ny","type":"blocks","created_at":"2026-02-11T16:15:38.805195-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-2jk","title":"Extract shared SourceFileProvider to deduplicate file reading","description":"Both ContextPacker::build_file_contexts() and WorkPacketGenerator::extract_symbols_from_files() independently read files from disk and iterate lines. This duplicates I/O when both are called in sequence (e.g. pack_initial calls the generator then builds its own contexts).\n\nFix: Extract a SourceFileProvider struct that:\n1. Caches file content in a HashMap\u003cPathBuf, String\u003e on first read\n2. Provides methods: get_content(path) -\u003e \u0026str, get_header(path, lines: usize) -\u003e \u0026str, get_lines_around(path, line, context) -\u003e \u0026str\n3. Is shared between WorkPacketGenerator and ContextPacker via reference\n\nThis eliminates redundant disk reads and provides a single point for file access patterns.\n\nFiles: coordination/src/work_packet/generator.rs, coordination/src/context_packer/packer.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:24.141768-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:24.141768-06:00"}
{"id":"beefcake-swarm-3kk","title":"Configure rig-core client timeouts","description":"The Implementer and Validator create rig-core CompletionsClient instances without configuring timeouts. If the inference server hangs (GPU OOM, SLURM preemption, network partition), the HTTP request blocks indefinitely and the orchestrator loop stalls.\n\nFix: Check rig-core's client builder for timeout configuration:\n1. Set connect_timeout (5s) and request_timeout (5min for 72B reasoning, 2min for 14B fast)\n2. Add these as fields in SwarmConfig per endpoint\n3. If rig-core doesn't support timeouts directly, wrap the implement/validate calls with tokio::time::timeout()\n\nAlso consider: retry logic for transient HTTP failures (502, 503 from inference server starting up).\n\nFiles: crates/swarm-agents/src/implementer.rs, crates/swarm-agents/src/validator.rs, crates/swarm-agents/src/config.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:34.003768-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:34.003768-06:00"}
{"id":"beefcake-swarm-3qg","title":"Fix redundant verifier run in orchestrator loop","description":"The orchestrator loop in main.rs runs the verifier TWICE per retry iteration: once at the end of iteration N (line 253) to check implementer output, then again at the start of iteration N+1 (line 217) to build retry context for pack_retry(). Rust compilation is expensive (~seconds per run); doubling it wastes time and cluster resources.\n\nFix: Carry the VerifierReport forward from the end of each loop iteration into the next via Option\u003cVerifierReport\u003e. Only run the verifier once per iteration. The report from the failed iteration already contains everything pack_retry() needs.\n\nFiles: crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:26.495938-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:26.495938-06:00"}
{"id":"beefcake-swarm-481","title":"Evaluate DSRs (dspy-rs) for structured LLM pipeline optimization","description":"DSRs (https://dsrs.herumbshandilya.com/) is a Rust-native rewrite of the DSPy framework for programming robust LM-powered applications. It provides typed Signatures, composable Modules, Predictors, and Optimizers (COPRO, MIPROv2, GEPA) for automatically improving LLM prompts and pipelines.\n\nCritically, DSRs already uses rig-core as its LM backend — the same crate swarm-agents uses for Implementer and Validator. This means integration could be relatively seamless.\n\nKey opportunities for beefcake-swarm:\n\n1. **Signature-based prompting**: Replace the hand-rolled format_work_packet() prompt builder with typed DSRs Signatures. This gives structured input/output contracts that the framework can optimize automatically.\n\n2. **Prompt optimization**: Use DSRs optimizers to automatically tune the implementer and validator prompts. Instead of manually iterating on prompt wording, COPRO/MIPROv2 can search for better prompts given a set of examples and a metric (e.g. verifier pass rate).\n\n3. **Evaluation framework**: DSRs' evaluate module could replace or augment the validator's pass/fail heuristic (starts_with PASS) with a more robust evaluation pipeline.\n\n4. **Pipeline composition**: The swarm loop (pack -\u003e implement -\u003e verify -\u003e validate) maps naturally to DSRs' Module composition pattern, potentially simplifying the orchestrator.\n\nInvestigation steps:\n1. Add dspy-rs = \"0.7\" to swarm-agents/Cargo.toml\n2. Define Signatures for the implementer task (input: WorkPacket fields, output: code changes) and validator task (input: diff, output: pass/fail + feedback)\n3. Wrap Implementer and Validator as DSRs Modules\n4. Evaluate whether DSRs Predictors can replace the raw rig-core prompt() calls\n5. Prototype an optimizer run on a set of known-good/bad code changes to auto-tune prompts\n\nRisks:\n- DSRs is in beta (v0.7.3) — API may have breaking changes\n- Optimizer training requires a dataset of examples with ground truth\n- May add significant dependency weight (arrow, parquet deps)\n- Unclear if DSRs supports local llama.cpp endpoints natively (needs OpenAI-compatible API adapter)\n\nReference: https://github.com/krypticmouse/DSRs, https://crates.io/crates/dspy-rs, https://docs.rs/dspy-rs\n\nDepends on: agent traits extraction (needed to wrap agents as DSRs Modules)","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:15:30.482492-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:15:30.482492-06:00","dependencies":[{"issue_id":"beefcake-swarm-481","depends_on_id":"beefcake-swarm-7ny","type":"blocks","created_at":"2026-02-11T16:15:39.14492-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-4j8","title":"Use git status -z for robust porcelain parsing","description":"FileWalker::modified_files() and WorktreeBridge merge checks parse 'git status --porcelain' output by slicing at [3..]. While porcelain v1 format is stable for normal cases, renamed files produce 'R  old -\u003e new' format, and filenames containing spaces or special characters can cause incorrect parsing.\n\nFix: Switch to 'git status -z --porcelain' which uses NUL byte separators instead of newlines, handles renames as two separate NUL-separated entries, and correctly handles filenames with spaces, quotes, and unicode characters. Parse by splitting on \\0 instead of \\n.\n\nFiles: coordination/src/context_packer/file_walker.rs, coordination/src/work_packet/generator.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:36.271461-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:36.271461-06:00"}
{"id":"beefcake-swarm-5iz","title":"Persist EscalationState across crashes","description":"EscalationState is purely in-memory. If the orchestrator crashes at iteration 5 of 6, the next run starts fresh at iteration 1, losing all error history, escalation records, and iteration counts. This causes:\n- Infinite loops if the crash is triggered by a specific payload\n- Lost 'learning' from previous error patterns\n- Incorrect escalation decisions (tier budgets reset)\n\nFix: After each call to escalation.record_iteration(), serialize the EscalationState to a JSON file inside the worktree directory (e.g. \u003cworktree\u003e/.beefcake-state.json). On loop startup, check if the state file exists in the worktree and deserialize it to resume.\n\nImplementation:\n1. Add save_to_file(\u0026self, path: \u0026Path) -\u003e Result\u003c()\u003e to EscalationState\n2. Add load_from_file(path: \u0026Path) -\u003e Result\u003cOption\u003cSelf\u003e\u003e to EscalationState\n3. In main.rs, after creating worktree, check for existing state file\n4. After each record_iteration(), save state\n\nFiles: coordination/src/escalation/state.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:29.339283-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:29.339283-06:00"}
{"id":"beefcake-swarm-687","title":"Add retry with backoff for transient git failures","description":"Git operations can fail transiently with index.lock errors when multiple processes access the same repo (e.g. worktree operations while the main repo is active, or concurrent prune/gc). Currently all git commands in WorktreeBridge and BeadsBridge fail immediately on any error.\n\nFix: Create a retry_git_command() helper that wraps Command execution with exponential backoff (3 retries, 100ms/500ms/2s delays). Apply specifically to git worktree add, git merge, and git commit operations which are most susceptible to lock contention. Only retry on stderr containing 'index.lock' or 'Unable to create'.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:42.798648-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:42.798648-06:00"}
{"id":"beefcake-swarm-7g0","title":"Deploy beefcake-swarm to ai-proxy LXC","description":"Clone repo to ai-proxy (ssh root@100.105.113.58), build workspace, configure endpoints. Verify cargo build --workspace succeeds on the LXC. Set up systemd service or SLURM job for orchestrator.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:27.161098-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:27.161098-06:00","dependencies":[{"issue_id":"beefcake-swarm-7g0","depends_on_id":"beefcake-swarm-7jt","type":"blocks","created_at":"2026-02-11T15:32:56.697608-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-7go","title":"Detect and clean zombie branches on startup","description":"If the orchestrator crashes mid-loop, /tmp may clean the worktree directory but the swarm/\u003cissue_id\u003e branch persists in the repo. On next run, git worktree add -b fails with 'A branch named swarm/... already exists' and the agent gets permanently stuck on that issue.\n\nFix: On startup (before the main loop), scan for orphaned swarm/* branches that have no corresponding worktree directory. For each orphan: attempt git branch -D to delete it. Also check git worktree list --porcelain for stale entries and run git worktree prune. This requires the remove_worktree() method from the worktree cleanup issue.\n\nAdd a WorktreeBridge::cleanup_stale() method that:\n1. Runs git worktree prune\n2. Lists all branches matching swarm/*\n3. For each, checks if worktree_path(id) exists\n4. If not, force-deletes the branch\n\nCall cleanup_stale() in main() before entering the issue-picking loop.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:21.043384-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:21.043384-06:00","dependencies":[{"issue_id":"beefcake-swarm-7go","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.551142-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-7jt","title":"Add coordination crate integration tests for standalone build","description":"The coordination crate was copied from beefcake2. Verify all existing tests pass in the new standalone context. Fix any path assumptions or missing dependencies. Run cargo test -p coordination.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:30.152182-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:30.152182-06:00"}
{"id":"beefcake-swarm-7ny","title":"Extract agent traits for dependency injection and testability","description":"Implementer and Validator are concrete structs that make real HTTP calls to inference endpoints. The orchestrator loop in main.rs instantiates them directly, making it impossible to unit test the loop logic without a running inference server.\n\nFix: Define traits in a new module (e.g. crates/swarm-agents/src/agents.rs):\n\npub trait ImplementerAgent {\n    async fn implement(\u0026self, task_description: \u0026str) -\u003e Result\u003cString\u003e;\n}\n\npub trait ValidatorAgent {\n    async fn validate(\u0026self, diff: \u0026str) -\u003e Result\u003cValidationResult\u003e;\n}\n\nHave the existing Implementer and Validator implement these traits. Refactor main.rs to accept trait objects (Box\u003cdyn ImplementerAgent\u003e) or use generics. This enables mock implementations for testing.\n\nConsider using mockall or manual mock structs for integration tests of the orchestrator loop.\n\nFiles: crates/swarm-agents/src/implementer.rs, crates/swarm-agents/src/validator.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:27.012071-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:27.012071-06:00"}
{"id":"beefcake-swarm-8nm","title":"Build context packer for agent context windows","description":"Agents need a repo packer to build context windows. Options: tree-sitter AST extraction, repomap (Aider-style), or custom Rust walker. Must respect .gitignore, count tokens, fit in model context. Can leverage indexing/index_flow_v2.py for semantic search.","status":"closed","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:13.558286-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.325665-06:00","closed_at":"2026-02-11T16:02:59.325665-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-a3y","title":"Improve token counting accuracy (bytes vs chars)","description":"WorkPacket::estimated_tokens() uses json.len() / 4 where String::len() returns byte count, not character count. For pure ASCII Rust code this is accurate, but multi-byte UTF-8 characters (unicode identifiers, emoji in comments, non-ASCII strings) cause byte count to overestimate character count, which then underestimates token count.\n\nAdditionally, the 4-chars-per-token heuristic is rough. JSON serialization adds overhead (field names, braces, escaping) that inflates the count vs what the LLM tokenizer actually sees.\n\nFix (incremental):\n1. Short term: Switch to json.chars().count() / 4 for slightly better accuracy\n2. Medium term: Use tiktoken-rs or a BPE tokenizer for the specific model family\n3. Add a safety margin (e.g. budget * 0.9) to avoid edge-case context overflow\n\nFiles: coordination/src/work_packet/types.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:30.728451-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:30.728451-06:00"}
{"id":"beefcake-swarm-a8m","title":"Add merge conflict test for WorktreeBridge","description":"WorktreeBridge tests cover create and list but not the merge conflict scenario, which is the most operationally dangerous path. When the main branch moves forward with a conflicting change while the worktree branch also makes changes, merge_and_remove() will fail — and the cleanup behavior needs to be verified.\n\nFix: Add test case to worktree_bridge.rs::tests:\n1. Create a worktree\n2. Commit a change to a file on the main branch\n3. Commit a conflicting change to the same file in the worktree\n4. Call merge_and_remove() — assert it returns Err\n5. Verify the worktree still exists (not accidentally deleted)\n6. Call remove_worktree() — assert it cleans up (depends on worktree cleanup method)\n\nAlso test: merge_and_remove() with uncommitted changes (should fail with descriptive error).\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:37.969298-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:37.969298-06:00","dependencies":[{"issue_id":"beefcake-swarm-a8m","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.919132-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-ago","title":"Set up CI with GitHub Actions","description":"Add .github/workflows/ci.yml with cargo check, cargo test, cargo clippy, cargo fmt --check. Cache cargo registry and target dir. Consider separate jobs for coordination and swarm-agents.","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:34.906223-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:34.906223-06:00"}
{"id":"beefcake-swarm-ayy","title":"Add GBNF grammar constraints for structured LLM output","description":"When JSON adherence is flaky from llama-server, use GBNF grammar constraints. Add grammar parameter support to implementer and validator agents. Define grammars for common output formats (code blocks, pass/fail verdicts, structured feedback).","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:23.009266-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:23.009266-06:00"}
{"id":"beefcake-swarm-djc","title":"Migrate coordination crate from anyhow to thiserror","description":"The coordination crate is a library but uses anyhow::Result in some internal functions. Library crates should provide structured error types via thiserror so consumers can match on specific error variants, while anyhow is appropriate for application binaries (swarm-agents).\n\nFix: Define error enums with thiserror for each coordination module:\n- VerifierError (GateTimeout, CommandFailed, ParseError)\n- EscalationError (BudgetExhausted, InvalidTransition)\n- ContextPackerError (FileWalkFailed, TokenBudgetExceeded)\n- WorkPacketError (GitCommandFailed, SymbolExtractionFailed)\n\nKeep anyhow in swarm-agents binary for ergonomic error propagation.\n\nFiles: coordination/src/verifier/, coordination/src/escalation/, coordination/src/context_packer/, coordination/src/work_packet/\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:26.440288-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:26.440288-06:00"}
{"id":"beefcake-swarm-dxt","title":"Atomic issue claiming to prevent race conditions","description":"The orchestrator has a check-then-act race: it calls list_open(), sorts by priority, picks the first issue, then calls update_status(in_progress). If two orchestrator instances run simultaneously (or two swarm loops), both will pick the same P1 issue, leading to duplicate work, git conflicts, and wasted inference credits.\n\nFix: Either implement an atomic claim_next_available() in BeadsBridge that combines list+claim in a single operation, or handle the case where update_status returns 'already claimed' and retry with the next issue. Consider adding a locking mechanism (file lock or beads-level CAS).\n\nFiles: crates/swarm-agents/src/beads_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:38.686478-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:38.686478-06:00"}
{"id":"beefcake-swarm-e3c","title":"Create monitoring dashboard for swarm operations","description":"Extend infrastructure/gpu-dashboard.py or create new tool to monitor: active agent tasks, inference endpoint health, beads issue throughput, escalation frequency. Could use beads_viewer (bv) robot mode for metrics.","status":"open","priority":3,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:38.541669-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:38.541669-06:00"}
{"id":"beefcake-swarm-ez1","title":"Add tracing spans with #[instrument] to key methods","description":"Current logging is flat — all log lines are at the same level with no hierarchical grouping. It's hard to correlate which logs belong to which iteration, issue, or git operation when reviewing output.\n\nFix: Add #[tracing::instrument] attributes to key methods:\n- ContextPacker::pack_initial(bead_id, objective) — span includes bead_id\n- ContextPacker::pack_retry(bead_id, ...) — span includes bead_id and iteration\n- WorktreeBridge::create(issue_id) — span includes issue_id\n- WorktreeBridge::merge_and_remove(issue_id) — span includes issue_id\n- Verifier::run_pipeline() — span includes working_dir\n- Implementer::implement() — span includes model name\n\nAdd skip directives for large parameters (e.g. task_description content). This creates nested spans visible in structured log output (JSON) or tracing-subscriber's hierarchical formatter.\n\nFiles: coordination/src/context_packer/packer.rs, crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:29.189788-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:29.189788-06:00"}
{"id":"beefcake-swarm-lzb","title":"Implement escalation ladder: Implementer → Integrator → Cloud → Human","description":"Wire the coordination crate's escalation engine into swarm-agents. Implementer tries 14B first, escalates to 72B Integrator, then Cloud Council (external API), finally Human. Use existing EscalationEngine and SwarmTier types from coordination/src/escalation/.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:26.789193-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:26.789193-06:00","dependencies":[{"issue_id":"beefcake-swarm-lzb","depends_on_id":"beefcake-swarm-tup","type":"blocks","created_at":"2026-02-11T15:32:56.607478-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-mu1","title":"Implement graceful shutdown with worktree cleanup","description":"The orchestrator has no signal handler. If killed via SIGINT (Ctrl+C) or SIGTERM (deployment, systemd stop) while a worktree is active, the worktree remains on disk and registered in git, causing disk space leaks and 'already checked out' errors on restart.\n\nFix: Use tokio::signal::ctrl_c() and tokio::signal::unix::signal(SignalKind::terminate()) to catch shutdown signals. When received:\n1. Set a shutdown flag (AtomicBool or tokio::sync::watch)\n2. Check the flag at the top of each loop iteration\n3. On shutdown: log the in-progress issue ID, call worktree_bridge.remove_worktree(), update beads status back to 'open', then exit cleanly\n\nConsider wrapping the active worktree path in an Arc\u003cMutex\u003cOption\u003cString\u003e\u003e\u003e so the signal handler knows what to clean up. Requires the remove_worktree() method from the worktree cleanup issue.\n\nFiles: crates/swarm-agents/src/main.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:25.932582-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:25.932582-06:00","dependencies":[{"issue_id":"beefcake-swarm-mu1","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.683284-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-nu2","title":"Adapt flywheel for SLURM/NFS patterns","description":"Review forked agentic_coding_flywheel_setup submodule. Extract useful prompts, task decomposition strategies, tool configurations. Discard Docker/cloud assumptions, adapt for SLURM scheduler and NFS shared storage.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:23.624475-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:23.624475-06:00"}
{"id":"beefcake-swarm-ost","title":"Priority-scored context trimming in ContextPacker","description":"ContextPacker::trim_to_budget() drops file_contexts from the end via pop(). This happens to work correctly because WorkPacketGenerator inserts error contexts first (highest priority) and file header contexts last (lowest priority). But this ordering guarantee is implicit and fragile — any change to insertion order in a different module breaks trimming priority silently.\n\nFix: Add a priority field to FileContext (or use an enum: Error \u003e Modified \u003e Header \u003e Reference). Before trimming, sort file_contexts by priority (lowest priority last). Then pop() is guaranteed to drop the least important context first regardless of insertion order.\n\nAlternative: Instead of modifying FileContext, partition into priority buckets and trim from the lowest bucket first.\n\nFiles: coordination/src/context_packer/packer.rs, coordination/src/work_packet/types.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:32.774693-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:32.774693-06:00"}
{"id":"beefcake-swarm-r93","title":"Wire beads_bridge to orchestrator main loop","description":"Connect beads_bridge.rs to the main orchestrator loop. List open issues, pick highest priority, update status to in_progress, close on completion. Use br CLI --json output for machine-readable parsing.","status":"closed","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:20.297648-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.372575-06:00","closed_at":"2026-02-11T16:02:59.372575-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-rb2","title":"Add worktree cleanup method for merge failure recovery","description":"WorktreeBridge::merge_and_remove() bails on merge conflict (line 140), leaving the worktree on disk and the swarm/\u003cid\u003e branch in the repo. The orchestrator exits with an error (line 306), creating zombie worktrees that block future attempts on the same issue (create() checks for existing worktree on line 74).\n\nFix: Add a remove_worktree(issue_id) method that force-removes the worktree and force-deletes the branch (git worktree remove --force + git branch -D). Use this in the orchestrator failure path so cleanup happens even when merge fails.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:30.568197-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:30.568197-06:00"}
{"id":"beefcake-swarm-rzr","title":"Integrate Gastown for workspace isolation","description":"Wire up gastown CLI calls from swarm-agents orchestrator. Create worktrees per agent task on NFS (/cluster/shared/wt/\u003cissue_id\u003e). Prevent file conflicts for parallel agents. Commands: gastown create, gastown merge.","status":"closed","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:16.884368-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.350146-06:00","closed_at":"2026-02-11T16:02:59.350146-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-tup","title":"Implement 2-agent loop MVP (orchestrator → implementer → verifier → validator)","description":"Core loop: orchestrator picks beads issue, creates gastown worktree, runs implementer (72B), deterministic verifier (fmt/clippy/test), blind validator (14B). If pass: merge+close. If fail: update notes, retry.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:10.010034-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:10.010034-06:00","dependencies":[{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-r93","type":"blocks","created_at":"2026-02-11T15:32:56.348232-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-rzr","type":"blocks","created_at":"2026-02-11T15:32:56.434885-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-8nm","type":"blocks","created_at":"2026-02-11T15:32:56.520579-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-ty0","title":"Use structured error fields in tracing macros","description":"Error logging uses string interpolation: error!('Failed to create worktree: {e}'). This embeds the error message in the format string, making it impossible for log aggregators (Loki, Datadog) to parse the error type separately from the message.\n\nFix: Use structured fields in tracing macros throughout main.rs and worktree_bridge.rs:\n- error!(error = %e, issue_id = %id, 'Failed to create worktree') — Display format\n- error!(error = ?e, issue_id = %id, 'Failed to create worktree') — Debug format (more detail)\n- warn!(iteration, feedback = %result.feedback, 'Validator FAILED')\n\nThis allows querying logs by error type, issue_id, or iteration number independently.\n\nFiles: crates/swarm-agents/src/main.rs, crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:31.658991-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:31.658991-06:00","dependencies":[{"issue_id":"beefcake-swarm-ty0","depends_on_id":"beefcake-swarm-ez1","type":"blocks","created_at":"2026-02-11T16:15:39.033017-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-wpe","title":"Implement DSR prompt optimization (deferred)","description":"Dynamic System Reasoning for optimizing agent prompts based on success/failure feedback. Deferred from initial implementation. Track in backlog for future iteration.","status":"open","priority":4,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:41.835271-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:41.835271-06:00"}
{"id":"beefcake-swarm-xv9","title":"Handle detached HEAD in WorkPacketGenerator","description":"WorkPacketGenerator::git_branch() uses 'git rev-parse --abbrev-ref HEAD' which returns the literal string 'HEAD' when in detached HEAD state (common in CI, after checkout of a specific commit, or in freshly created worktrees before the first commit).\n\nThis means the WorkPacket.branch field becomes 'HEAD' which is misleading in the prompt sent to the LLM and may confuse the agent about which branch it's working on.\n\nFix: If git_branch() returns 'HEAD', fall back to:\n1. Check for CI env vars (CI_COMMIT_REF_NAME, GITHUB_HEAD_REF, BRANCH_NAME)\n2. Try 'git name-rev --name-only HEAD'\n3. Use 'detached@\u003cshort-sha\u003e' as a last resort\n\nFiles: coordination/src/work_packet/generator.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:23.225461-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:23.225461-06:00"}
{"id":"beefcake-swarm-y2d","title":"Sanitize issue IDs to prevent path traversal","description":"WorktreeBridge::worktree_path() does base_dir.join(issue_id) with no validation. If issue_id contains path separators (e.g. ../../etc or ../../../tmp/evil), it could write worktrees outside the base directory.\n\nFix: Add validate_issue_id() that rejects any ID not matching [a-zA-Z0-9_-]. Call it in create(), merge_and_remove(), and worktree_path(). Beads IDs are alphanumeric-with-hyphens so this won't break real usage.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:34.634992-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:34.634992-06:00"}
