{"id":"beefcake-swarm-0ko","title":"Add GBNF grammar-constrained structured output for implementer patches","description":"The apply_implementer_changes stub (main.rs:91-110) is the #1 blocker identified by all 4 consulted models. llama.cpp supports GBNF grammars and automatic JSON schema conversion via the json_schema body field in /v1/chat/completions. Define an ImplementerOutput JSON schema (list of file edits with paths, search/replace blocks or unified hunks, optional reasoning). Pass schema via json_schema field to force structured output. Implement real patch application by parsing the validated JSON response. Fallback: search-replace blocks (Aider pattern). Files: crates/swarm-agents/src/main.rs (apply_implementer_changes), crates/swarm-agents/src/implementer.rs, new file crates/swarm-agents/src/patch_applicator.rs. Reference: https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md","status":"open","priority":0,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:48:49.241001-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:48:49.241001-06:00"}
{"id":"beefcake-swarm-0l5","title":"Make WorkPacket constraints configurable","description":"WorkPacketGenerator has hardcoded default constraints (line 46: 'No new dependencies without explicit approval', 'Don't break existing public API'). These are baked into the binary and cannot be overridden per-task.\n\nThis is problematic for tasks that intentionally require adding dependencies, changing public API, or have different LOC limits.\n\nFix: Move default constraints into SwarmConfig (or a new PackerConfig). Allow per-issue constraint overrides via beads issue labels or metadata. The ContextPacker should accept optional extra constraints that merge with (or replace) the defaults.\n\nConsider: constraints could come from beads issue fields, a .beefcake.toml project config, or CLI flags.\n\nFiles: coordination/src/work_packet/generator.rs, crates/swarm-agents/src/config.rs, coordination/src/context_packer/packer.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:20.875919-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:20.875919-06:00"}
{"id":"beefcake-swarm-0lh","title":"Study Goose/Aider/OpenHands patch engines for apply_implementer_changes","description":"Research patch application patterns from existing tools: (1) Aider: search-replace blocks with \u003c\u003c\u003c\u003c SEARCH / ==== REPLACE / \u003e\u003e\u003e\u003e markers, (2) OpenHands/SWE-agent: unified diff with patch command, (3) Goose by Block: closest existing product to our swarm (study their architecture and patch engine). Document pros/cons of each approach for our structured output pipeline. Determine which pattern best complements GBNF-constrained JSON output. G3-Pro identified Goose as most architecturally similar. GPT-5.2-Codex recommended OpenHands diff-structured outputs. Deliverable: design doc + recommendation.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:50.77437-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:50.77437-06:00","dependencies":[{"issue_id":"beefcake-swarm-0lh","depends_on_id":"beefcake-swarm-0ko","type":"blocks","created_at":"2026-02-11T16:50:22.704981-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-10m","title":"Upgrade ContextPacker to span-aware error-driven retrieval (Potpie pattern)","description":"All 4 models identified that current context packing (first 30 lines per file) misses critical information. Steal Potpie pattern: on verifier failures, use rustc error spans to retrieve relevant code regions. Specifically: (1) Parse rustc JSON error spans (file + line range), (2) Pack ±80 lines around each error span, (3) Include trait definitions and impl blocks referenced in trait bound errors, (4) Include callers/callees of symbols in error messages. Depends on tree-sitter integration for symbol graph. Files: coordination/src/context_packer/packer.rs (pack_retry enhancement), coordination/src/verifier/report.rs (span extraction from rustc JSON). Depends on tree-sitter issue.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:13.808572-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:13.808572-06:00","dependencies":[{"issue_id":"beefcake-swarm-10m","depends_on_id":"beefcake-swarm-5bk","type":"blocks","created_at":"2026-02-11T16:50:22.460109-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-2fd","title":"Add integration test for orchestrator loop","description":"There is no test that validates the full orchestrator loop data flow: ContextPacker -\u003e format_work_packet -\u003e Implementer -\u003e apply_changes -\u003e Verifier -\u003e Validator. Each component is tested in isolation but the wiring between them is only exercised by running the real binary against a live inference server.\n\nFix: Create a test in crates/swarm-agents/tests/ that:\n1. Uses mock Implementer (returns a fixed code change)\n2. Uses mock Validator (returns PASS)\n3. Sets up a real temp git repo with a known-broken Rust file\n4. Runs the loop for 1 iteration\n5. Verifies: pack_initial called, implementer received formatted prompt, verifier ran, validator received diff, issue closed\n\nThis depends on extracting agent traits (beefcake-swarm-AGENT_TRAITS_ID) so mocks can be injected.\n\nFiles: crates/swarm-agents/tests/ (new), crates/swarm-agents/src/main.rs\nDepends on: agent traits extraction\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:35.314013-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:35.314013-06:00","dependencies":[{"issue_id":"beefcake-swarm-2fd","depends_on_id":"beefcake-swarm-7ny","type":"blocks","created_at":"2026-02-11T16:15:38.805195-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-2jk","title":"Extract shared SourceFileProvider to deduplicate file reading","description":"Both ContextPacker::build_file_contexts() and WorkPacketGenerator::extract_symbols_from_files() independently read files from disk and iterate lines. This duplicates I/O when both are called in sequence (e.g. pack_initial calls the generator then builds its own contexts).\n\nFix: Extract a SourceFileProvider struct that:\n1. Caches file content in a HashMap\u003cPathBuf, String\u003e on first read\n2. Provides methods: get_content(path) -\u003e \u0026str, get_header(path, lines: usize) -\u003e \u0026str, get_lines_around(path, line, context) -\u003e \u0026str\n3. Is shared between WorkPacketGenerator and ContextPacker via reference\n\nThis eliminates redundant disk reads and provides a single point for file access patterns.\n\nFiles: coordination/src/work_packet/generator.rs, coordination/src/context_packer/packer.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:24.141768-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:24.141768-06:00"}
{"id":"beefcake-swarm-3is","title":"Unified Knowledge Graph Integration","description":"Root epic: Bridge documentation and code for the agent swarm via a Unified Knowledge Graph backed by SurrealDB (RocksDB storage engine). Covers infrastructure, code graph ingestion, document ingestion, WorkPacket integration, self-learning loop, benchmarking, and MCP tool exposure.","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:01.118138-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:01.118138-06:00","labels":["epic:ukg"]}
{"id":"beefcake-swarm-3is.1","title":"UKG: Infrastructure \u0026 Deployment","description":"Sub-epic 1: Deploy SurrealDB on ai-proxy LXC, design schema, create Rust client, investigate SurrealDB vs direct RocksDB for existing stores.","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:18.779902-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:18.779902-06:00","labels":["epic:ukg","infrastructure"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:18.780758-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.1.1","title":"Research SurrealDB deployment for HPC/LXC","description":"Research SurrealDB deployment best practices via PAL consensus. Compare embedded (RocksDB backend) vs networked (TiKV), auth/TLS setup, systemd config, resource requirements for ai-proxy LXC. Include SurrealDB 2.x architecture (compute/storage separation). Output: deployment decision document.","notes":"PAL consensus prompt: Compare SurrealDB embedded (RocksDB) vs networked (TiKV) for a single-node LXC deployment. Consider: memory footprint, persistence guarantees, auth setup, systemd integration. Expected output: config template + systemd unit.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:17.677849-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:17.677849-06:00","labels":["delegate:pal-consensus","epic:ukg","infrastructure","research"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1.1","depends_on_id":"beefcake-swarm-3is.1","type":"parent-child","created_at":"2026-02-13T08:11:17.678895-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.1.2","title":"Deploy SurrealDB on ai-proxy LXC","description":"Install SurrealDB on ai-proxy (100.105.113.58). Systemd service, network binding for 10.0.0.0/24 + Tailscale. Namespaces: beefcake/knowledge_graph (prod), beefcake/benchmark. Verify connectivity from vasp nodes.","notes":"Human task — SSH required. Share creds via /cluster/shared/ai/surreal.env. Bind to 0.0.0.0:8000 with auth enabled.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:17.907875-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:17.907875-06:00","labels":["delegate:human","epic:ukg","infrastructure"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1.2","depends_on_id":"beefcake-swarm-3is.1","type":"parent-child","created_at":"2026-02-13T08:11:17.908763-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.1.2","depends_on_id":"beefcake-swarm-3is.1.1","type":"blocks","created_at":"2026-02-13T08:11:57.889269-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.1.3","title":"Design \u0026 deploy SurrealDB schema","description":"Create SurrealQL schema for code graph (function, struct, trait, module, file + calls/defines/imports/implements edges), doc graph (document, chunk + contains edges), and bridge edges (documents, mentions). Vector indexes for 3584-dim nomic embeddings (MTREE cosine). Deploy to prod namespace.","notes":"Use PAL chat with g3-pro (Librarian role). Output: schema.surql file. Consider: SCHEMAFULL tables, DEFINE INDEX for vector search, DEFINE FIELD with type constraints.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:18.129206-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:18.129206-06:00","labels":["delegate:g3-pro","design","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1.3","depends_on_id":"beefcake-swarm-3is.1","type":"parent-child","created_at":"2026-02-13T08:11:18.130299-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.1.3","depends_on_id":"beefcake-swarm-3is.1.2","type":"blocks","created_at":"2026-02-13T08:11:58.387109-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.1.4","title":"Add Rust SurrealDB client to coordination crate","description":"Add surrealdb crate to coordination/Cargo.toml. New module coordination/src/knowledge_graph/client.rs with KgClient struct (connection pool, health check, CRUD). Follow coordination/src/state/store.rs Arc pattern for SharedKgClient. Config via SURREALDB_URL env var.","notes":"Pattern reference: coordination/src/state/store.rs for Arc\u003cRwLock\u003c\u003e\u003e shared state. The KgClient should support both embedded and remote connections for testing vs production.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:18.359372-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:18.359372-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1.4","depends_on_id":"beefcake-swarm-3is.1","type":"parent-child","created_at":"2026-02-13T08:11:18.360181-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.1.4","depends_on_id":"beefcake-swarm-3is.1.2","type":"blocks","created_at":"2026-02-13T08:11:58.738076-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.1.5","title":"Investigate SurrealDB vs direct RocksDB for Error KB and Archival Memory","description":"Investigate whether SurrealDB (which uses RocksDB as its default storage backend) should replace the direct RocksDB approach proposed in beefcake-swarm-3r9 (Error Pattern KB) and beefcake-swarm-b30 (Archival Memory). Compare: query flexibility (SurrealQL graph+vector vs manual KV), latency overhead (SurrealDB query layer vs direct RocksDB), operational simplicity (one DB vs two). Reference SurrealDB architecture.","notes":"PAL consensus. Key insight: SurrealDB uses RocksDB under the hood — so the question is whether the query layer overhead is worth the graph/vector capabilities. If yes, 3r9 and b30 migrate to SurrealDB. If no, keep direct RocksDB for latency-sensitive operations (per-issue state) and use SurrealDB for cross-issue knowledge only.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:18.591062-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:18.591062-06:00","labels":["delegate:pal-consensus","epic:ukg","research"],"dependencies":[{"issue_id":"beefcake-swarm-3is.1.5","depends_on_id":"beefcake-swarm-3is.1","type":"parent-child","created_at":"2026-02-13T08:11:18.597752-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.2","title":"UKG: Code Graph Ingestion (codegraph-rust)","description":"Sub-epic 2: Research and deploy codegraph-rust for AST-level code graph ingestion into SurrealDB. Share tree-sitter parsing with context_packer.","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:19.002308-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:19.002308-06:00","labels":["epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.2","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:19.003111-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.2.1","title":"Research codegraph-rust capabilities","description":"Deep-dive jakedismo/codegraph-rust: node/edge types, SurrealDB storage support (look for surrealdb_storage.rs), incremental update support, tree-sitter dependency, performance on ~21K LOC Rust codebase. Determine if fork needed.","notes":"PAL chat with g3-pro (Librarian). Output: feature matrix + config example. Check GitHub repo for SurrealDB native support vs needing a custom adapter.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:18.835498-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:18.835498-06:00","labels":["delegate:g3-pro","epic:ukg","research"],"dependencies":[{"issue_id":"beefcake-swarm-3is.2.1","depends_on_id":"beefcake-swarm-3is.2","type":"parent-child","created_at":"2026-02-13T08:11:18.8364-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.2.2","title":"Deploy codegraph-rust indexer for beefcake-swarm","description":"Configure codegraph-rust to index coordination/ and crates/swarm-agents/ into SurrealDB. If no native SurrealDB support, write Rust adapter in indexing/. Must be idempotent. Validate: ~300+ functions, ~80+ structs/enums, ~20+ traits.","notes":"Idempotency via deterministic IDs (hash of file path + symbol name). Run as CLI or integrate into build pipeline.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:19.062001-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:19.062001-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.2.2","depends_on_id":"beefcake-swarm-3is.2","type":"parent-child","created_at":"2026-02-13T08:11:19.062906-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.2.2","depends_on_id":"beefcake-swarm-3is.1.3","type":"blocks","created_at":"2026-02-13T08:11:58.98291-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.2.2","depends_on_id":"beefcake-swarm-3is.2.1","type":"blocks","created_at":"2026-02-13T08:11:59.09046-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.2.3","title":"Share tree-sitter parser between codegraph and context_packer","description":"Ensure one tree-sitter parse per file shared between codegraph ingestion and context packing (avoid duplicate parsing). Create shared AstIndex module in coordination. Coordinate with beefcake-swarm-5bk.","notes":"Synergy with beefcake-swarm-5bk (tree-sitter-rust for AST-aware context packing). Both need parsed ASTs — share the cache.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:19.294317-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:19.294317-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.2.3","depends_on_id":"beefcake-swarm-3is.2","type":"parent-child","created_at":"2026-02-13T08:11:19.295423-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.2.3","depends_on_id":"beefcake-swarm-3is.2.2","type":"blocks","created_at":"2026-02-13T08:11:59.31202-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.3","title":"UKG: Document/Semantic Ingestion (CocoIndex → SurrealDB)","description":"Sub-epic 3: Extend CocoIndex pipeline with SurrealDB target for dual-write (pgvector + SurrealDB). Build bridge edges linking doc chunks to code symbols.","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:19.225419-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:19.225419-06:00","labels":["epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.3","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:19.226271-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.3.1","title":"Research CocoIndex custom Target for SurrealDB","description":"Research CocoIndex Target interface for custom SurrealDB target. Can we run dual-write (Postgres + SurrealDB) in a single flow? Validate against actual CocoIndex v1 API (not the outdated sketch in COCOINDEX_GRAPH_RAG.md).","notes":"PAL consensus. The existing indexing/index_flow_v2.py uses @flow_def pattern. Output: validated implementation approach. Check CocoIndex docs for custom target/sink interface.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:19.526154-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:19.526154-06:00","labels":["delegate:pal-consensus","epic:ukg","research"],"dependencies":[{"issue_id":"beefcake-swarm-3is.3.1","depends_on_id":"beefcake-swarm-3is.3","type":"parent-child","created_at":"2026-02-13T08:11:19.527018-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.3.2","title":"Implement dual-write CocoIndex flow (pgvector + SurrealDB)","description":"Implement SurrealDBTarget for CocoIndex. Create indexing/targets/surreal_target.py. Modify or create index_flow_v3.py for dual-write. Python (keep working pipeline). Deterministic IDs for idempotency. Config via env vars.","notes":"Keep existing pgvector pipeline working. Dual-write means both stores get identical data for benchmarking. SURREALDB_URL, SURREALDB_NS, SURREALDB_DB env vars.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:19.752501-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:19.752501-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.3.2","depends_on_id":"beefcake-swarm-3is.3","type":"parent-child","created_at":"2026-02-13T08:11:19.753306-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.3.2","depends_on_id":"beefcake-swarm-3is.1.3","type":"blocks","created_at":"2026-02-13T08:11:59.533936-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.3.2","depends_on_id":"beefcake-swarm-3is.3.1","type":"blocks","created_at":"2026-02-13T08:11:59.639447-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.3.3","title":"Build bridge edge processor (doc↔code linking)","description":"Post-processing step creating bridge edges between doc chunks and code symbols. Strategy 1: regex-based symbol extraction from doc text. Strategy 2 (future): embedding similarity. Write in Rust (indexing/bridge-linker/). SurrealQL: RELATE chunk-\u003edocuments-\u003efunction.","notes":"Start with regex strategy (cheaper, deterministic). Match function/struct/trait names found in doc text to code graph nodes. Run after both code and doc ingestion complete.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:19.979691-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:19.979691-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.3.3","depends_on_id":"beefcake-swarm-3is.3","type":"parent-child","created_at":"2026-02-13T08:11:19.980519-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.3.3","depends_on_id":"beefcake-swarm-3is.2.2","type":"blocks","created_at":"2026-02-13T08:11:59.874972-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.3.3","depends_on_id":"beefcake-swarm-3is.3.2","type":"blocks","created_at":"2026-02-13T08:11:59.976578-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.4","title":"UKG: WorkPacket \u0026 Coordination Integration","description":"Sub-epic 4: Wire knowledge graph into WorkPacket enrichment, Router task classification, and Escalation signals. THE critical integration layer.","status":"open","priority":0,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:19.441072-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:19.441072-06:00","labels":["epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.4","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:19.441894-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.4.1","title":"Design KG query interface for WorkPacket enrichment","description":"Design how KG queries populate WorkPacket.relevant_heuristics and relevant_playbooks. Define: SurrealQL queries per error category, token budget allocation (2K implementer, 4K integrator, 8K cloud), integration point in pipeline (pack_retry vs generate). Output: Rust trait + SurrealQL query library.","notes":"PAL consensus — this is THE critical architectural decision. All 3 frontier models weigh in. Files: coordination/src/context_packer/packer.rs, coordination/src/work_packet/types.rs","status":"open","priority":0,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:20.223004-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:20.223004-06:00","labels":["delegate:pal-consensus","design","epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.4.1","depends_on_id":"beefcake-swarm-3is.4","type":"parent-child","created_at":"2026-02-13T08:11:20.223784-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.4.2","title":"Implement KG-enriched WorkPacket generation","description":"Wire KG queries into ContextPacker::pack_retry(). Populate relevant_heuristics and relevant_playbooks. Optional (graceful degradation if KG unavailable). Add KgEnricher trait. Gate behind --knowledge-graph CLI flag. Respect tier token budgets (2K/4K/8K).","notes":"Files: coordination/src/context_packer/packer.rs, coordination/src/work_packet/types.rs. Must degrade gracefully — KG enrichment is additive, never blocking.","status":"open","priority":0,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:20.444056-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:20.444056-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.4.2","depends_on_id":"beefcake-swarm-3is.4","type":"parent-child","created_at":"2026-02-13T08:11:20.444825-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.4.2","depends_on_id":"beefcake-swarm-3is.4.1","type":"blocks","created_at":"2026-02-13T08:12:00.233616-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.4.2","depends_on_id":"beefcake-swarm-3is.1.4","type":"blocks","created_at":"2026-02-13T08:12:00.348129-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.4.2","depends_on_id":"beefcake-swarm-3is.2.2","type":"blocks","created_at":"2026-02-13T08:12:00.453619-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.4.3","title":"KG-aware Router task classification","description":"Enhance task_classifier.rs with KG structural signals: fan-in (callers count), coupling (importers count), trait impl complexity. Add kg_complexity_boost() method. Additive — keyword heuristic remains as fallback.","notes":"File: coordination/src/router/task_classifier.rs. Pure deterministic logic. KG signals are optional boost factors, never replace existing classification.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:20.685128-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:20.685128-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.4.3","depends_on_id":"beefcake-swarm-3is.4","type":"parent-child","created_at":"2026-02-13T08:11:20.686032-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.4.3","depends_on_id":"beefcake-swarm-3is.4.2","type":"blocks","created_at":"2026-02-13T08:12:00.70076-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.4.4","title":"KG-informed escalation signals","description":"New EscalationReason variants: HighFanIn, MultipleImplementors. New thresholds in EscalationConfig: fan_in_threshold (default 5), implementor_threshold (default 3). Pure deterministic logic, no LLM calls.","notes":"File: coordination/src/escalation/engine.rs. Additive new variants — existing escalation reasons unchanged.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:20.928312-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:20.928312-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.4.4","depends_on_id":"beefcake-swarm-3is.4","type":"parent-child","created_at":"2026-02-13T08:11:20.929189-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.4.4","depends_on_id":"beefcake-swarm-3is.4.2","type":"blocks","created_at":"2026-02-13T08:12:00.937163-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.5","title":"UKG: Self-Learning Loop","description":"Sub-epic 5: Error Pattern KB, fix pattern capture, tiered archival memory (Letta/MemGPT pattern). Agents learn from past fixes and avoid repeating failures.","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:19.653632-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:19.653632-06:00","labels":["epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.5","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:19.654561-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.5.1","title":"Research self-learning architectures for coding agents","description":"Research how SWE-agent, OpenHands, Goose, Cursor, Aider implement learning from past fixes. How do they store fix patterns, retrieve them, define success signals, prevent learning bad patterns? Also research DSPy feedback loops. Output: comparison matrix + recommended architecture.","notes":"PAL consensus + also try Cloud Council tool (test its functionality). This is the highest-value research task. Compare: episodic memory, RAG over past runs, structured pattern extraction, embedding-based retrieval.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:21.159109-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:21.159109-06:00","labels":["delegate:pal-consensus","epic:ukg","research"],"dependencies":[{"issue_id":"beefcake-swarm-3is.5.1","depends_on_id":"beefcake-swarm-3is.5","type":"parent-child","created_at":"2026-02-13T08:11:21.160211-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.5.2","title":"Implement Error Pattern KB in SurrealDB","description":"Build Error Pattern KB as SurrealDB graph nodes. Schema: fix_pattern node (error_signature, original_code, fix_diff, strategy, model_tier, iterations, success_count). Edges: fix_pattern-\u003efixed-\u003efunction. Query: top-3 matching past fixes by error category + file + symbols, ranked by success rate + recency. Relates to beefcake-swarm-3r9 (may supersede or complement depending on 1.5 investigation).","notes":"Storage decision depends on 1.5 investigation. If SurrealDB wins, this supersedes 3r9. If not, this becomes a SurrealDB mirror of the RocksDB store for cross-issue queries.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:21.384524-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:21.384524-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.5.2","depends_on_id":"beefcake-swarm-3is.5","type":"parent-child","created_at":"2026-02-13T08:11:21.385456-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.2","depends_on_id":"beefcake-swarm-3is.5.1","type":"blocks","created_at":"2026-02-13T08:12:01.182534-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.2","depends_on_id":"beefcake-swarm-3is.1.4","type":"blocks","created_at":"2026-02-13T08:12:01.28039-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.2","depends_on_id":"beefcake-swarm-3is.1.5","type":"blocks","created_at":"2026-02-13T08:12:01.377201-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.5.3","title":"Wire learning feedback into orchestrator loop","description":"After successful verification, capture: diff, error categories fixed, model tier, iteration count. Store as fix pattern via KgClient. Non-blocking, fire-and-forget. Also track per-model success rates by error category for routing optimization.","notes":"File: crates/swarm-agents/src/main.rs. Must be non-blocking — never slow down the main loop. Use tokio::spawn for async storage.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:21.602965-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:21.602965-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.5.3","depends_on_id":"beefcake-swarm-3is.5","type":"parent-child","created_at":"2026-02-13T08:11:21.60382-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.3","depends_on_id":"beefcake-swarm-3is.5.2","type":"blocks","created_at":"2026-02-13T08:12:01.589416-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.3","depends_on_id":"beefcake-swarm-3is.4.2","type":"blocks","created_at":"2026-02-13T08:12:01.687371-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.5.4","title":"Tiered archival memory (Letta/MemGPT pattern)","description":"Per-issue memory in SurrealDB: working memory = WorkPacket, archival = prior diffs/reports/decisions per bead_id. On pack_retry, recall failed approaches. Promotion rules: successful fixes → shared KB, failures → scoped to bead_id. Relates to beefcake-swarm-b30 (may supersede or complement depending on 1.5 investigation).","notes":"Storage decision depends on 1.5 investigation. Key pattern: working memory (current context) vs archival memory (past attempts). Prevents retrying the same failed approach.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:21.842369-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:21.842369-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.5.4","depends_on_id":"beefcake-swarm-3is.5","type":"parent-child","created_at":"2026-02-13T08:11:21.843653-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.4","depends_on_id":"beefcake-swarm-3is.5.2","type":"blocks","created_at":"2026-02-13T08:12:01.9143-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.5.4","depends_on_id":"beefcake-swarm-3is.1.5","type":"blocks","created_at":"2026-02-13T08:12:02.015741-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.6","title":"UKG: Benchmarking (pgvector vs SurrealDB)","description":"Sub-epic 6: Design and run benchmarks comparing pgvector and SurrealDB on latency, quality, throughput. Produce migration decision.","status":"open","priority":2,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:19.863588-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:19.863588-06:00","labels":["benchmark","epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.6","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:19.864354-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.6.1","title":"Design benchmark framework (pgvector vs SurrealDB)","description":"Design benchmark comparing pgvector and SurrealDB: vector search latency (p50/p95/p99), hybrid search quality (graph+vector vs vector-only), write throughput, query flexibility. Define 10 benchmark queries from real agent workloads.","notes":"PAL chat with gpt-5.2 (Manager role — task decomposition). Queries should cover: similar error lookup, symbol dependency traversal, hybrid doc+code search, write-heavy pattern storage.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:22.062597-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:22.062597-06:00","labels":["benchmark","delegate:gpt-5.2","design","epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.6.1","depends_on_id":"beefcake-swarm-3is.6","type":"parent-child","created_at":"2026-02-13T08:11:22.063533-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.6.1","depends_on_id":"beefcake-swarm-3is.3.2","type":"blocks","created_at":"2026-02-13T08:12:02.247737-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.6.1","depends_on_id":"beefcake-swarm-3is.2.2","type":"blocks","created_at":"2026-02-13T08:12:02.345617-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.6.2","title":"Run benchmarks and produce comparison report","description":"Implement benchmark harness in Rust. Run against both stores with identical data. Produce comparison report with latency histograms, quality scores, operational assessment.","notes":"Use criterion.rs for microbenchmarks. Run on ai-proxy LXC where both stores live. Report format: markdown with embedded charts (plotters crate).","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:22.282273-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:22.282273-06:00","labels":["benchmark","delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.6.2","depends_on_id":"beefcake-swarm-3is.6","type":"parent-child","created_at":"2026-02-13T08:11:22.283136-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.6.2","depends_on_id":"beefcake-swarm-3is.6.1","type":"blocks","created_at":"2026-02-13T08:12:02.563757-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.6.3","title":"Migration decision (pgvector → SurrealDB)","description":"Based on benchmark results + 1.5 investigation, make go/no-go on full pgvector→SurrealDB migration. Frontier consensus + human sign-off required.","notes":"PAL consensus. This is a blocking decision for long-term architecture. Three outcomes: (1) full migration, (2) keep both with role separation, (3) stay with pgvector.","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:22.500512-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:22.500512-06:00","labels":["delegate:pal-consensus","design","epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.6.3","depends_on_id":"beefcake-swarm-3is.6","type":"parent-child","created_at":"2026-02-13T08:11:22.501405-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.6.3","depends_on_id":"beefcake-swarm-3is.6.2","type":"blocks","created_at":"2026-02-13T08:12:02.779652-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.6.3","depends_on_id":"beefcake-swarm-3is.1.5","type":"blocks","created_at":"2026-02-13T08:12:02.875491-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.7","title":"UKG: MCP Tool Exposure","description":"Sub-epic 7: Expose KG as MCP tools: search_knowledge_graph (hybrid vector+graph), query_code_graph (structural), store_knowledge (agent write-back).","status":"open","priority":1,"issue_type":"epic","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:09:20.084551-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:09:20.084551-06:00","labels":["epic:ukg"],"dependencies":[{"issue_id":"beefcake-swarm-3is.7","depends_on_id":"beefcake-swarm-3is","type":"parent-child","created_at":"2026-02-13T08:09:20.085333-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.7.1","title":"Add search_knowledge_graph MCP tool","description":"New MCP tool in coordination/src/main.rs. Accepts query string, returns semantically similar code + related doc chunks + graph-traversed dependencies. Hybrid search: embed query via nomic on vasp-02:8080, then vector + graph traversal. Gate behind --knowledge-graph flag.","notes":"Follow ask_rust_architect pattern at coordination/src/main.rs line 563. Return format: ranked list of (code_symbol, relevance_score, related_docs, dependency_chain).","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:22.724167-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:22.724167-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.7.1","depends_on_id":"beefcake-swarm-3is.7","type":"parent-child","created_at":"2026-02-13T08:11:22.725051-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.7.1","depends_on_id":"beefcake-swarm-3is.1.4","type":"blocks","created_at":"2026-02-13T08:12:03.104917-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.7.1","depends_on_id":"beefcake-swarm-3is.2.2","type":"blocks","created_at":"2026-02-13T08:12:03.202286-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.7.2","title":"Add query_code_graph MCP tool (structural queries)","description":"Pure structural queries: 'what calls X?', 'what implements Y?', 'what imports Z?'. Deterministic, no embeddings needed. Useful for Planner agent (beefcake-swarm-j4l).","notes":"SurrealQL graph traversal only. No vector search. Fast path for structural questions. Expose as separate tool for clarity.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:22.946001-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:22.946001-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.7.2","depends_on_id":"beefcake-swarm-3is.7","type":"parent-child","created_at":"2026-02-13T08:11:22.946844-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.7.2","depends_on_id":"beefcake-swarm-3is.7.1","type":"blocks","created_at":"2026-02-13T08:12:03.425022-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3is.7.3","title":"Add store_knowledge MCP tool (agent write-back)","description":"Agents write knowledge back to KG: design decisions, architecture notes, 'this function is tricky because...'. Schema: agent_note with confidence field (decays over time). Lower weight than code-derived facts.","notes":"Confidence decay: new notes start at 1.0, decay by 0.1 per week. Agent-contributed knowledge is always lower-ranked than code-derived facts in search results.","status":"open","priority":3,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-13T08:11:23.193209-06:00","created_by":"TheFermiSea","updated_at":"2026-02-13T08:11:23.193209-06:00","labels":["delegate:claude-subagent","epic:ukg","implementation"],"dependencies":[{"issue_id":"beefcake-swarm-3is.7.3","depends_on_id":"beefcake-swarm-3is.7","type":"parent-child","created_at":"2026-02-13T08:11:23.194068-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-3is.7.3","depends_on_id":"beefcake-swarm-3is.7.1","type":"blocks","created_at":"2026-02-13T08:12:03.704176-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-3kk","title":"Configure rig-core client timeouts","description":"The Implementer and Validator create rig-core CompletionsClient instances without configuring timeouts. If the inference server hangs (GPU OOM, SLURM preemption, network partition), the HTTP request blocks indefinitely and the orchestrator loop stalls.\n\nFix: Check rig-core's client builder for timeout configuration:\n1. Set connect_timeout (5s) and request_timeout (5min for 72B reasoning, 2min for 14B fast)\n2. Add these as fields in SwarmConfig per endpoint\n3. If rig-core doesn't support timeouts directly, wrap the implement/validate calls with tokio::time::timeout()\n\nAlso consider: retry logic for transient HTTP failures (502, 503 from inference server starting up).\n\nFiles: crates/swarm-agents/src/implementer.rs, crates/swarm-agents/src/validator.rs, crates/swarm-agents/src/config.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:34.003768-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:34.003768-06:00"}
{"id":"beefcake-swarm-3qg","title":"Fix redundant verifier run in orchestrator loop","description":"The orchestrator loop in main.rs runs the verifier TWICE per retry iteration: once at the end of iteration N (line 253) to check implementer output, then again at the start of iteration N+1 (line 217) to build retry context for pack_retry(). Rust compilation is expensive (~seconds per run); doubling it wastes time and cluster resources.\n\nFix: Carry the VerifierReport forward from the end of each loop iteration into the next via Option\u003cVerifierReport\u003e. Only run the verifier once per iteration. The report from the failed iteration already contains everything pack_retry() needs.\n\nFiles: crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:26.495938-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:26.495938-06:00"}
{"id":"beefcake-swarm-3r9","title":"Build Error Pattern Knowledge Base for cross-issue learning","description":"UNANIMOUS CONSENSUS (4/4 models)\n\nThe swarm currently has NO memory across issues. EscalationState tracks error history for one issue only. The same borrow checker error pattern might be solved 50 times without the swarm ever learning the fix.\n\nImplement a persistent Error Pattern KB:\n1. After each successful fix, store: (error_signature, original_code_snippet, fix_diff, strategy_description, model_tier, iterations_to_resolve)\n2. Before each implementation attempt, query the KB for similar past errors (match on ErrorCategory + key tokens from message + file structure)\n3. Include top-3 matching successful strategies in WorkPacket.relevant_playbooks (field already exists but is always empty)\n\nStorage: Use the existing RocksDB infrastructure in coordination/state/. Add a new column family for fix patterns.\n\nError signature should include: ErrorCategory, rustc error code, key tokens from the error message (e.g. 'cannot borrow', 'lifetime mismatch'), affected symbol types.\n\nThis is essentially few-shot learning from the swarm's own history. G3-Pro calls it 'Compiler RAG'. Opus calls it 'the missing flywheel'.\n\nAlso track per-model success rates by error category to inform routing decisions (e.g. if 14B has \u003c40% success on Lifetime errors, escalate immediately).\n\nFiles: coordination/src/state/ (new KB module), coordination/src/context_packer/packer.rs, coordination/src/work_packet/generator.rs","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:31.480361-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:31.480361-06:00"}
{"id":"beefcake-swarm-3rl","title":"Revisit AdalFlow/TextGrad prompt optimization after 50+ completed issues","description":"All 4 models agreed: prompt optimization (AdalFlow, TextGrad) is premature before we have data. Revisit after the swarm has completed 50+ issues with logged prompts and outcomes. At that point: (1) Build scoring function from validator pass rate + iteration count, (2) Run A/B tests on prompt variations, (3) Evaluate whether systematic prompt tuning beats manual iteration. Depends on SWE-bench eval harness being built first. Backlog until data exists.","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:50:02.027259-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:50:02.027259-06:00","dependencies":[{"issue_id":"beefcake-swarm-3rl","depends_on_id":"beefcake-swarm-yhx","type":"blocks","created_at":"2026-02-11T16:50:22.577043-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-481","title":"Evaluate DSRs (dspy-rs) for structured LLM pipeline optimization","description":"DSRs (https://dsrs.herumbshandilya.com/) is a Rust-native rewrite of the DSPy framework for programming robust LM-powered applications. It provides typed Signatures, composable Modules, Predictors, and Optimizers (COPRO, MIPROv2, GEPA) for automatically improving LLM prompts and pipelines.\n\nCritically, DSRs already uses rig-core as its LM backend — the same crate swarm-agents uses for Implementer and Validator. This means integration could be relatively seamless.\n\nKey opportunities for beefcake-swarm:\n\n1. **Signature-based prompting**: Replace the hand-rolled format_work_packet() prompt builder with typed DSRs Signatures. This gives structured input/output contracts that the framework can optimize automatically.\n\n2. **Prompt optimization**: Use DSRs optimizers to automatically tune the implementer and validator prompts. Instead of manually iterating on prompt wording, COPRO/MIPROv2 can search for better prompts given a set of examples and a metric (e.g. verifier pass rate).\n\n3. **Evaluation framework**: DSRs' evaluate module could replace or augment the validator's pass/fail heuristic (starts_with PASS) with a more robust evaluation pipeline.\n\n4. **Pipeline composition**: The swarm loop (pack -\u003e implement -\u003e verify -\u003e validate) maps naturally to DSRs' Module composition pattern, potentially simplifying the orchestrator.\n\nInvestigation steps:\n1. Add dspy-rs = \"0.7\" to swarm-agents/Cargo.toml\n2. Define Signatures for the implementer task (input: WorkPacket fields, output: code changes) and validator task (input: diff, output: pass/fail + feedback)\n3. Wrap Implementer and Validator as DSRs Modules\n4. Evaluate whether DSRs Predictors can replace the raw rig-core prompt() calls\n5. Prototype an optimizer run on a set of known-good/bad code changes to auto-tune prompts\n\nRisks:\n- DSRs is in beta (v0.7.3) — API may have breaking changes\n- Optimizer training requires a dataset of examples with ground truth\n- May add significant dependency weight (arrow, parquet deps)\n- Unclear if DSRs supports local llama.cpp endpoints natively (needs OpenAI-compatible API adapter)\n\nReference: https://github.com/krypticmouse/DSRs, https://crates.io/crates/dspy-rs, https://docs.rs/dspy-rs\n\nDepends on: agent traits extraction (needed to wrap agents as DSRs Modules)","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:15:30.482492-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:15:30.482492-06:00","dependencies":[{"issue_id":"beefcake-swarm-481","depends_on_id":"beefcake-swarm-7ny","type":"blocks","created_at":"2026-02-11T16:15:39.14492-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-4j8","title":"Use git status -z for robust porcelain parsing","description":"FileWalker::modified_files() and WorktreeBridge merge checks parse 'git status --porcelain' output by slicing at [3..]. While porcelain v1 format is stable for normal cases, renamed files produce 'R  old -\u003e new' format, and filenames containing spaces or special characters can cause incorrect parsing.\n\nFix: Switch to 'git status -z --porcelain' which uses NUL byte separators instead of newlines, handles renames as two separate NUL-separated entries, and correctly handles filenames with spaces, quotes, and unicode characters. Parse by splitting on \\0 instead of \\n.\n\nFiles: coordination/src/context_packer/file_walker.rs, coordination/src/work_packet/generator.rs\nFound by: G3-Pro deep review","status":"closed","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:36.271461-06:00","created_by":"TheFermiSea","updated_at":"2026-02-12T11:14:25.714746-06:00","closed_at":"2026-02-12T11:14:25.714746-06:00","close_reason":"Fixed in PR #1 review commit a26ba46"}
{"id":"beefcake-swarm-4p5","title":"Iteration delta memory (structured context evolution)","description":"UNIQUE INSIGHT from GPT-5.2-Codex and Opus\n\nReplace flat 'previous_attempts' strings with structured iteration deltas that capture WHAT CHANGED between iterations, not just what happened.\n\nAdd IterationDelta struct:\n- fixed_errors: Vec\u003cErrorCategory\u003e — what improved\n- new_errors: Vec\u003cErrorCategory\u003e — what regressed  \n- files_modified: Vec\u003cString\u003e — what was touched\n- hypothesis: Option\u003cString\u003e — what the model claimed it was doing (extracted from response)\n- result_summary: String — 'borrow error fixed, but introduced lifetime error in return type'\n- strategy_used: String — 'added Arc wrapper' or 'changed lifetime annotation'\n\nInclude only the last 2-3 deltas in context (not full history). The model needs to see 'you fixed X but broke Y' not 'here is everything that ever went wrong'.\n\nAlso add provenance tags to FileContext (source: compiler_error, diff, dependency, import) and decay: reduce weight of previously included context not re-referenced by new errors.\n\nFiles: coordination/src/work_packet/types.rs (new IterationDelta type), coordination/src/escalation/state.rs, coordination/src/context_packer/packer.rs","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:35:37.668508-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:35:37.668508-06:00"}
{"id":"beefcake-swarm-5bk","title":"Integrate tree-sitter-rust for AST-aware context packing","description":"Replace regex/line-based symbol extraction in ContextPacker with tree-sitter-rust AST parsing. Currently build_file_contexts() takes first 30 lines of each file (packer.rs:94-136) which misses critical context. With tree-sitter: extract fn signatures, impl blocks, trait definitions, struct fields at AST level. On verifier failures, use rustc error spans to pack ±80 lines around each span + referenced symbol definitions. This dramatically improves context quality and reduces iterations. Deps: tree-sitter, tree-sitter-rust crates. Files: coordination/src/context_packer/packer.rs, coordination/src/context_packer/file_walker.rs, new file coordination/src/context_packer/ast_index.rs. All 4 consulted models (G3-Pro, GPT-5.2-Codex, GPT-5.2, Claude Opus 4.5) flagged this as highest priority. Opus rated it P0.","status":"open","priority":0,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:48:44.470879-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:48:44.470879-06:00"}
{"id":"beefcake-swarm-5iz","title":"Persist EscalationState across crashes","description":"EscalationState is purely in-memory. If the orchestrator crashes at iteration 5 of 6, the next run starts fresh at iteration 1, losing all error history, escalation records, and iteration counts. This causes:\n- Infinite loops if the crash is triggered by a specific payload\n- Lost 'learning' from previous error patterns\n- Incorrect escalation decisions (tier budgets reset)\n\nFix: After each call to escalation.record_iteration(), serialize the EscalationState to a JSON file inside the worktree directory (e.g. \u003cworktree\u003e/.beefcake-state.json). On loop startup, check if the state file exists in the worktree and deserialize it to resume.\n\nImplementation:\n1. Add save_to_file(\u0026self, path: \u0026Path) -\u003e Result\u003c()\u003e to EscalationState\n2. Add load_from_file(path: \u0026Path) -\u003e Result\u003cOption\u003cSelf\u003e\u003e to EscalationState\n3. In main.rs, after creating worktree, check for existing state file\n4. After each record_iteration(), save state\n\nFiles: coordination/src/escalation/state.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:29.339283-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:29.339283-06:00"}
{"id":"beefcake-swarm-5uq","title":"Add Adversarial Breaker agent for pre-merge red-teaming","description":"STRONG CONSENSUS (3/4 models)\n\nBefore merging, a dedicated agent should actively try to BREAK the implementation by generating edge-case tests, weird inputs, concurrency interleavings, and invalid states.\n\nThe SwarmTier::Adversary already exists in escalation/state.rs but isn't integrated into the loop.\n\nImplementation:\n1. After Verifier passes (all green), invoke the Adversary agent\n2. Give it ONLY the diff and public API signatures (no implementation context — truly adversarial)\n3. It generates: proptest harnesses, edge-case unit tests, boundary condition checks\n4. Run these generated tests through the Verifier\n5. If any Adversary test fails, reject the implementation and feed the failing test back to the Implementer\n\nThis catches 'compiles but is wrong' — the biggest failure mode that compilation gates miss.\n\nG3-Pro: 'Active Sabotage / Mutation Testing'. Opus: 'Adversary actively tries to break the code'.\n\nFiles: crates/swarm-agents/src/ (new adversary module), crates/swarm-agents/src/main.rs","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:43.60542-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:43.60542-06:00","dependencies":[{"issue_id":"beefcake-swarm-5uq","depends_on_id":"beefcake-swarm-j4l","type":"blocks","created_at":"2026-02-11T16:35:50.750484-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-687","title":"Add retry with backoff for transient git failures","description":"Git operations can fail transiently with index.lock errors when multiple processes access the same repo (e.g. worktree operations while the main repo is active, or concurrent prune/gc). Currently all git commands in WorktreeBridge and BeadsBridge fail immediately on any error.\n\nFix: Create a retry_git_command() helper that wraps Command execution with exponential backoff (3 retries, 100ms/500ms/2s delays). Apply specifically to git worktree add, git merge, and git commit operations which are most susceptible to lock contention. Only retry on stderr containing 'index.lock' or 'Unable to create'.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:42.798648-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:42.798648-06:00"}
{"id":"beefcake-swarm-7g0","title":"Deploy beefcake-swarm to ai-proxy LXC","description":"Clone repo to ai-proxy (ssh root@100.105.113.58), build workspace, configure endpoints. Verify cargo build --workspace succeeds on the LXC. Set up systemd service or SLURM job for orchestrator.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:27.161098-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:27.161098-06:00","dependencies":[{"issue_id":"beefcake-swarm-7g0","depends_on_id":"beefcake-swarm-7jt","type":"blocks","created_at":"2026-02-11T15:32:56.697608-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-7go","title":"Detect and clean zombie branches on startup","description":"If the orchestrator crashes mid-loop, /tmp may clean the worktree directory but the swarm/\u003cissue_id\u003e branch persists in the repo. On next run, git worktree add -b fails with 'A branch named swarm/... already exists' and the agent gets permanently stuck on that issue.\n\nFix: On startup (before the main loop), scan for orphaned swarm/* branches that have no corresponding worktree directory. For each orphan: attempt git branch -D to delete it. Also check git worktree list --porcelain for stale entries and run git worktree prune. This requires the remove_worktree() method from the worktree cleanup issue.\n\nAdd a WorktreeBridge::cleanup_stale() method that:\n1. Runs git worktree prune\n2. Lists all branches matching swarm/*\n3. For each, checks if worktree_path(id) exists\n4. If not, force-deletes the branch\n\nCall cleanup_stale() in main() before entering the issue-picking loop.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:21.043384-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:21.043384-06:00","dependencies":[{"issue_id":"beefcake-swarm-7go","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.551142-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-7jt","title":"Add coordination crate integration tests for standalone build","description":"The coordination crate was copied from beefcake2. Verify all existing tests pass in the new standalone context. Fix any path assumptions or missing dependencies. Run cargo test -p coordination.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:30.152182-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:30.152182-06:00"}
{"id":"beefcake-swarm-7ny","title":"Extract agent traits for dependency injection and testability","description":"Implementer and Validator are concrete structs that make real HTTP calls to inference endpoints. The orchestrator loop in main.rs instantiates them directly, making it impossible to unit test the loop logic without a running inference server.\n\nFix: Define traits in a new module (e.g. crates/swarm-agents/src/agents.rs):\n\npub trait ImplementerAgent {\n    async fn implement(\u0026self, task_description: \u0026str) -\u003e Result\u003cString\u003e;\n}\n\npub trait ValidatorAgent {\n    async fn validate(\u0026self, diff: \u0026str) -\u003e Result\u003cValidationResult\u003e;\n}\n\nHave the existing Implementer and Validator implement these traits. Refactor main.rs to accept trait objects (Box\u003cdyn ImplementerAgent\u003e) or use generics. This enables mock implementations for testing.\n\nConsider using mockall or manual mock structs for integration tests of the orchestrator loop.\n\nFiles: crates/swarm-agents/src/implementer.rs, crates/swarm-agents/src/validator.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:27.012071-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:27.012071-06:00"}
{"id":"beefcake-swarm-8nm","title":"Build context packer for agent context windows","description":"Agents need a repo packer to build context windows. Options: tree-sitter AST extraction, repomap (Aider-style), or custom Rust walker. Must respect .gitignore, count tokens, fit in model context. Can leverage indexing/index_flow_v2.py for semantic search.","status":"closed","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:13.558286-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.325665-06:00","closed_at":"2026-02-11T16:02:59.325665-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-94s","title":"Evaluate llama-cpp-rs native bindings vs HTTP overhead","description":"Claude Opus 4.5 suggested evaluating llama-cpp-rs for native Rust bindings to llama.cpp, eliminating HTTP overhead. Currently we call llama.cpp via OpenAI-compatible HTTP API through rig-core. Evaluate: (1) Does llama-cpp-rs support grammar/GBNF constraints? (2) Latency improvement vs HTTP? (3) Can it coexist with SLURM job management? (4) Does it complicate the SLURM lifecycle (inference runs on compute nodes, orchestrator on controller)? Note: HTTP may actually be correct for our cluster architecture where inference and orchestration run on different nodes.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:50:05.882818-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:50:05.882818-06:00"}
{"id":"beefcake-swarm-a3y","title":"Improve token counting accuracy (bytes vs chars)","description":"WorkPacket::estimated_tokens() uses json.len() / 4 where String::len() returns byte count, not character count. For pure ASCII Rust code this is accurate, but multi-byte UTF-8 characters (unicode identifiers, emoji in comments, non-ASCII strings) cause byte count to overestimate character count, which then underestimates token count.\n\nAdditionally, the 4-chars-per-token heuristic is rough. JSON serialization adds overhead (field names, braces, escaping) that inflates the count vs what the LLM tokenizer actually sees.\n\nFix (incremental):\n1. Short term: Switch to json.chars().count() / 4 for slightly better accuracy\n2. Medium term: Use tiktoken-rs or a BPE tokenizer for the specific model family\n3. Add a safety margin (e.g. budget * 0.9) to avoid edge-case context overflow\n\nFiles: coordination/src/work_packet/types.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:30.728451-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:30.728451-06:00"}
{"id":"beefcake-swarm-a8m","title":"Add merge conflict test for WorktreeBridge","description":"WorktreeBridge tests cover create and list but not the merge conflict scenario, which is the most operationally dangerous path. When the main branch moves forward with a conflicting change while the worktree branch also makes changes, merge_and_remove() will fail — and the cleanup behavior needs to be verified.\n\nFix: Add test case to worktree_bridge.rs::tests:\n1. Create a worktree\n2. Commit a change to a file on the main branch\n3. Commit a conflicting change to the same file in the worktree\n4. Call merge_and_remove() — assert it returns Err\n5. Verify the worktree still exists (not accidentally deleted)\n6. Call remove_worktree() — assert it cleans up (depends on worktree cleanup method)\n\nAlso test: merge_and_remove() with uncommitted changes (should fail with descriptive error).\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:37.969298-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:37.969298-06:00","dependencies":[{"issue_id":"beefcake-swarm-a8m","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.919132-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-ago","title":"Set up CI with GitHub Actions","description":"Add .github/workflows/ci.yml with cargo check, cargo test, cargo clippy, cargo fmt --check. Cache cargo registry and target dir. Consider separate jobs for coordination and swarm-agents.","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:34.906223-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:34.906223-06:00"}
{"id":"beefcake-swarm-axn","title":"AST-aware context packing via tree-sitter","description":"UNANIMOUS CONSENSUS (4/4 models)\n\nThe current ContextPacker uses 'first 30 lines of each file' as context — this is spatial, not semantic. All 4 reviewing models flagged this as a critical weakness causing hallucinated APIs and wasted context budget.\n\nReplace with AST-aware context extraction:\n1. Integrate tree-sitter-rust for Rust AST parsing\n2. Extract semantic units: full function bodies at error spans, struct/enum definitions, trait bounds, impl blocks\n3. Score context by relevance: error spans \u003e call sites \u003e modified files \u003e imports \u003e headers\n4. Include symbol-to-file map so the LLM knows 'where to edit' without searching\n\nSpecific improvements to build_file_contexts():\n- Instead of first 30 lines, extract the function/impl containing the error span\n- Include trait definitions referenced by trait bound errors\n- Include callers/callees of modified functions\n- Score each FileContext with a priority (Error \u003e Modified \u003e Dependency \u003e Header)\n\nConsider: headless rust-analyzer integration as a higher-fidelity alternative to tree-sitter. Start with tree-sitter for speed, upgrade to RA later.\n\nDependencies: tree-sitter = '0.24', tree-sitter-rust\nFiles: coordination/src/context_packer/packer.rs, coordination/Cargo.toml","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:26.120968-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:26.120968-06:00"}
{"id":"beefcake-swarm-ayy","title":"Add GBNF grammar constraints for structured LLM output","description":"When JSON adherence is flaky from llama-server, use GBNF grammar constraints. Add grammar parameter support to implementer and validator agents. Define grammars for common output formats (code blocks, pass/fail verdicts, structured feedback).","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:23.009266-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:23.009266-06:00"}
{"id":"beefcake-swarm-b30","title":"Implement archival memory with recall for retries (Letta/MemGPT pattern)","description":"Steal Letta/MemGPT pattern: build RocksDB-backed tiered memory system. Working memory = current WorkPacket. Archival memory = queryable store of prior diffs, verifier reports, repeated compiler errors, decisions, design notes per bead_id. On pack_retry, recall relevant prior approaches that failed (FailedApproachIndex). Add memory promotion rules: successful fix patterns get promoted, failed approaches get stored with error context. Use existing RocksDB in coordination/src/state/. Add memory schema, summarizer hook, and recall policy. Files: coordination/src/state/ (new memory module), coordination/src/context_packer/packer.rs (recall integration). Medium effort, high payoff for multi-iteration issues.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:39.77938-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:39.77938-06:00"}
{"id":"beefcake-swarm-bbv","title":"Death spiral circuit breaker (revert on error increase)","description":"UNIQUE INSIGHT from G3-Pro, validated by GPT-5.2\n\nA common failure mode: the 72B model tries to 'fix' a compile error by refactoring the entire file, introducing 10 new errors. The current loop keeps trying to fix the growing pile of errors, wasting all iterations.\n\nImplement a circuit breaker in the orchestrator loop:\n1. After each Verifier run, compare error count to previous iteration\n2. If error_count(N) \u003e error_count(N-1) * 1.5 (50% increase), trigger circuit breaker\n3. Circuit breaker action: git revert to previous state, then retry with STRICT constraints:\n   - 'Change ONLY the line reported in the error'\n   - 'Do not refactor surrounding code'\n   - max_patch_loc reduced to 20\n4. If the strict retry also fails, escalate immediately (don't burn remaining budget)\n\nAlso enforce: if diff size exceeds max_patch_loc, reject the patch BEFORE running verifier. Don't waste compile time on oversized patches.\n\nGPT-5.2 adds: 'treat green-to-red regressions as negative progress' and 'use edit distance between error sets rather than just category comparison'.\n\nFiles: crates/swarm-agents/src/main.rs, coordination/src/escalation/state.rs","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:35:26.803399-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:35:26.803399-06:00"}
{"id":"beefcake-swarm-d15","title":"Add OpenTelemetry tracing spans to orchestrator loop","description":"No observability in the orchestrator loop means blind debugging when iterations fail. Add OpenTelemetry spans around: issue selection, worktree creation, context packing, implementer call, patch application, verifier pipeline, validator call, merge. Track metrics: pass rate per tier, iterations to green, tokens consumed, wallclock per phase, escalation frequency. Use tracing-opentelemetry + opentelemetry-otlp crates. Export to stdout/file initially, OTLP endpoint later. Files: crates/swarm-agents/Cargo.toml, crates/swarm-agents/src/main.rs. Claude Opus 4.5 rated this P0.","status":"open","priority":0,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:48:53.017261-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:48:53.017261-06:00"}
{"id":"beefcake-swarm-d1a","title":"Evaluate Kalosm for Rust-native LLM orchestration","description":"Kalosm is a Rust-native AI orchestration framework. G3-Pro flagged it as worth investigating. Evaluate: (1) Does it offer capabilities beyond rig-core? (2) Local embedding model support for retrieval/RAG, (3) Tool-calling patterns, (4) Integration with llama.cpp. Compare with current rig-core setup. If it offers embeddings without Python, could replace CocoIndex dependency. Low priority — only pursue if rig-core proves limiting.","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:58.112912-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:58.112912-06:00"}
{"id":"beefcake-swarm-djc","title":"Migrate coordination crate from anyhow to thiserror","description":"The coordination crate is a library but uses anyhow::Result in some internal functions. Library crates should provide structured error types via thiserror so consumers can match on specific error variants, while anyhow is appropriate for application binaries (swarm-agents).\n\nFix: Define error enums with thiserror for each coordination module:\n- VerifierError (GateTimeout, CommandFailed, ParseError)\n- EscalationError (BudgetExhausted, InvalidTransition)\n- ContextPackerError (FileWalkFailed, TokenBudgetExceeded)\n- WorkPacketError (GitCommandFailed, SymbolExtractionFailed)\n\nKeep anyhow in swarm-agents binary for ergonomic error propagation.\n\nFiles: coordination/src/verifier/, coordination/src/escalation/, coordination/src/context_packer/, coordination/src/work_packet/\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:26.440288-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:26.440288-06:00"}
{"id":"beefcake-swarm-dxt","title":"Atomic issue claiming to prevent race conditions","description":"The orchestrator has a check-then-act race: it calls list_open(), sorts by priority, picks the first issue, then calls update_status(in_progress). If two orchestrator instances run simultaneously (or two swarm loops), both will pick the same P1 issue, leading to duplicate work, git conflicts, and wasted inference credits.\n\nFix: Either implement an atomic claim_next_available() in BeadsBridge that combines list+claim in a single operation, or handle the case where update_status returns 'already claimed' and retry with the next issue. Consider adding a locking mechanism (file lock or beads-level CAS).\n\nFiles: crates/swarm-agents/src/beads_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:38.686478-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:38.686478-06:00"}
{"id":"beefcake-swarm-e3c","title":"Create monitoring dashboard for swarm operations","description":"Extend infrastructure/gpu-dashboard.py or create new tool to monitor: active agent tasks, inference endpoint health, beads issue throughput, escalation frequency. Could use beads_viewer (bv) robot mode for metrics.","status":"open","priority":3,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:38.541669-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:38.541669-06:00"}
{"id":"beefcake-swarm-ez1","title":"Add tracing spans with #[instrument] to key methods","description":"Current logging is flat — all log lines are at the same level with no hierarchical grouping. It's hard to correlate which logs belong to which iteration, issue, or git operation when reviewing output.\n\nFix: Add #[tracing::instrument] attributes to key methods:\n- ContextPacker::pack_initial(bead_id, objective) — span includes bead_id\n- ContextPacker::pack_retry(bead_id, ...) — span includes bead_id and iteration\n- WorktreeBridge::create(issue_id) — span includes issue_id\n- WorktreeBridge::merge_and_remove(issue_id) — span includes issue_id\n- Verifier::run_pipeline() — span includes working_dir\n- Implementer::implement() — span includes model name\n\nAdd skip directives for large parameters (e.g. task_description content). This creates nested spans visible in structured log output (JSON) or tracing-subscriber's hierarchical formatter.\n\nFiles: coordination/src/context_packer/packer.rs, crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:29.189788-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:29.189788-06:00"}
{"id":"beefcake-swarm-fxo","title":"Integrate DSRs as prompt policy optimization layer","description":"STRONG CONSENSUS (3/4 models, builds on existing beefcake-swarm-481)\n\nUse DSRs (dspy-rs) not as a per-agent prompt hack, but as a POLICY LAYER that optimizes how the swarm communicates with models.\n\nArchitecture:\n1. DSRs sits BETWEEN ContextPacker and LLM call\n2. Define typed Signatures for each agent role (Implementer, Validator, Planner, Adversary)\n3. Define reward signals from deterministic gates:\n   - +1.0 for all-green first try\n   - +0.2 for green in \u003c3 iterations with small patch\n   - -1.0 for regression introduced\n   - -0.5 for timeout/hang\n   - -0.3 for validator risk flag\n4. Treat prompt as: Template (stable) + Policy Parameters (learned)\n   - Learned params: plan-vs-code ratio, tests-first toggle, max patch aggressiveness, context ordering\n5. A/B test prompt variants using the existing ensemble infrastructure\n6. Store prompt versions with success rate metrics in RocksDB\n\nOffline optimization loop: replay past issues through DSRs optimizer to find better prompt configurations. Deploy optimized prompts, measure on new issues, iterate.\n\nDepends on: agent traits extraction (beefcake-swarm-7ny), DSRs evaluation (beefcake-swarm-481)\nFiles: crates/swarm-agents/src/ (prompt policy module), coordination/src/ensemble/","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:35:15.423884-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:35:15.423884-06:00","dependencies":[{"issue_id":"beefcake-swarm-fxo","depends_on_id":"beefcake-swarm-7ny","type":"blocks","created_at":"2026-02-11T16:35:50.515608-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-fxo","depends_on_id":"beefcake-swarm-481","type":"blocks","created_at":"2026-02-11T16:35:50.633539-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-i42","title":"Add explicit planning step for complex issues (RA.Aid pattern)","description":"Currently the orchestrator goes straight from issue to implementation (main.rs:229). For complex issues, a planning phase reduces iteration count. Steal RA.Aid Research-Plan-Act pattern: (1) Add complexity_score to issue classification based on error categories and file count, (2) For complex issues (\u003e3 files, trait/lifetime errors, escalated tasks): inject planning step where 72B model generates a concrete plan, (3) 14B Implementer executes the plan, (4) Store plan as artifact in RocksDB, include in WorkPacket on retry. Add plan field to WorkPacket struct. Low-medium effort, medium-high payoff. All 4 models recommended this pattern.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:23.350566-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:23.350566-06:00"}
{"id":"beefcake-swarm-j4l","title":"Add Planner agent with structured change contracts","description":"UNANIMOUS CONSENSUS (4/4 models: G3-Pro, GPT-5.2-Codex, GPT-5.2, Opus 4.5)\n\nThe current loop goes straight to code generation without formalizing intent. Add a Planner agent (can use the fast 14B model) that runs BEFORE the Implementer and produces a structured 'change contract':\n\n- Acceptance criteria (what must be true when done)\n- Invariants / behavioral promises (what must NOT change)\n- Files expected to change (scoping)\n- Risk classification (API break risk, concurrency risk, security risk)\n- Test plan: which tests to add/modify, what failure proves correctness\n\nThe contract becomes:\n1. A constraint for the Implementer (bounded search space)\n2. A checklist for the Validator (check against plan, not just 'does it look right')\n3. An audit trail (what was intended vs what happened)\n4. Partial rollback points (if step 3/5 fails, retry from step 3)\n\nImplementation: Add a PlannerAgent trait and struct in swarm-agents, produce a ChangeContract type in coordination/. The contract feeds into WorkPacket.constraints and WorkPacket.decisions. The Validator receives the contract alongside the diff.\n\nG3-Pro calls this 'Legislator-Executor'. GPT-5.2-Codex calls it '3-stage contract + selection'. Both identify it as the highest-impact architectural change.\n\nFiles: crates/swarm-agents/src/ (new planner module), coordination/src/ (new contract types), crates/swarm-agents/src/main.rs","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:20.665759-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:20.665759-06:00"}
{"id":"beefcake-swarm-jse","title":"Sandbox verification pipeline (treat agent code as untrusted)","description":"STRONG CONSENSUS (3/4 models)\n\nAgent-generated code can do ANYTHING — including filesystem deletion, network exfiltration, command execution in build.rs, or infinite loops in tests. On an HPC cluster with shared NFS, this is catastrophic.\n\nRun all verification gates in a sandbox:\n1. Use bubblewrap (bwrap) or firejail on Linux to sandbox cargo commands\n2. Restrictions: no network access, restricted filesystem (only worktree + target dirs), CPU/memory/time caps\n3. Per-test timeouts (not just per-gate — the existing gate_timeout_secs config isn't enforced)\n4. Kill process trees on timeout (not just the parent process)\n5. Detect 'test passed but took 10x longer than baseline' as suspicious\n\nAlso add: pre-check for dangerous patterns before running (new unsafe blocks, std::process::Command, std::fs::remove_dir_all, network calls).\n\nNote: VerifierConfig already has gate_timeout_secs (line 28 in pipeline.rs) but it's not enforced — gates use blocking Command::output() with no timeout.\n\nFiles: coordination/src/verifier/pipeline.rs, coordination/src/verifier/ (new sandbox module)","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:52.565254-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:52.565254-06:00"}
{"id":"beefcake-swarm-lzb","title":"Implement escalation ladder: Implementer → Integrator → Cloud → Human","description":"Wire the coordination crate's escalation engine into swarm-agents. Implementer tries 14B first, escalates to 72B Integrator, then Cloud Council (external API), finally Human. Use existing EscalationEngine and SwarmTier types from coordination/src/escalation/.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:26.789193-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:26.789193-06:00","dependencies":[{"issue_id":"beefcake-swarm-lzb","depends_on_id":"beefcake-swarm-tup","type":"blocks","created_at":"2026-02-11T15:32:56.607478-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-mu1","title":"Implement graceful shutdown with worktree cleanup","description":"The orchestrator has no signal handler. If killed via SIGINT (Ctrl+C) or SIGTERM (deployment, systemd stop) while a worktree is active, the worktree remains on disk and registered in git, causing disk space leaks and 'already checked out' errors on restart.\n\nFix: Use tokio::signal::ctrl_c() and tokio::signal::unix::signal(SignalKind::terminate()) to catch shutdown signals. When received:\n1. Set a shutdown flag (AtomicBool or tokio::sync::watch)\n2. Check the flag at the top of each loop iteration\n3. On shutdown: log the in-progress issue ID, call worktree_bridge.remove_worktree(), update beads status back to 'open', then exit cleanly\n\nConsider wrapping the active worktree path in an Arc\u003cMutex\u003cOption\u003cString\u003e\u003e\u003e so the signal handler knows what to clean up. Requires the remove_worktree() method from the worktree cleanup issue.\n\nFiles: crates/swarm-agents/src/main.rs\nDepends on: worktree cleanup method (beefcake-swarm-rb2)\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:25.932582-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:25.932582-06:00","dependencies":[{"issue_id":"beefcake-swarm-mu1","depends_on_id":"beefcake-swarm-rb2","type":"blocks","created_at":"2026-02-11T16:15:38.683284-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-nu2","title":"Adapt flywheel for SLURM/NFS patterns","description":"Review forked agentic_coding_flywheel_setup submodule. Extract useful prompts, task decomposition strategies, tool configurations. Discard Docker/cloud assumptions, adapt for SLURM scheduler and NFS shared storage.","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:23.624475-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:23.624475-06:00"}
{"id":"beefcake-swarm-ost","title":"Priority-scored context trimming in ContextPacker","description":"ContextPacker::trim_to_budget() drops file_contexts from the end via pop(). This happens to work correctly because WorkPacketGenerator inserts error contexts first (highest priority) and file header contexts last (lowest priority). But this ordering guarantee is implicit and fragile — any change to insertion order in a different module breaks trimming priority silently.\n\nFix: Add a priority field to FileContext (or use an enum: Error \u003e Modified \u003e Header \u003e Reference). Before trimming, sort file_contexts by priority (lowest priority last). Then pop() is guaranteed to drop the least important context first regardless of insertion order.\n\nAlternative: Instead of modifying FileContext, partition into priority buckets and trim from the lowest bucket first.\n\nFiles: coordination/src/context_packer/packer.rs, coordination/src/work_packet/types.rs\nFound by: G3-Pro deep review","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:13:32.774693-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:13:32.774693-06:00"}
{"id":"beefcake-swarm-ozx","title":"Evaluate TensorZero as Rust inference gateway (spike)","description":"TensorZero is a Rust-native inference gateway with structured output enforcement, model routing, and observability. G3-Pro said INTEGRATE IMMEDIATELY — it could replace SLURM endpoint discovery and manual health checks. Evaluate: (1) Does it support llama.cpp OpenAI-compatible API? (2) Does it handle health checks, failover, backoff? (3) Can it enforce JSON schema outputs? (4) Does it add observability we lack? If compatible, prototype replacing coordination/src/slurm/ endpoint management. If not, steal the structured output + routing patterns only. Compare with current rig-core setup. Time-box: 2-3 days for spike.","status":"open","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:05.750864-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:05.750864-06:00"}
{"id":"beefcake-swarm-pbk","title":"Structure validator feedback as actionable deltas (TextGrad pattern)","description":"Currently validator feedback (main.rs:287 result.feedback) goes into logs but does not systematically feed back into the next iteration prompt. Steal the TextGrad pattern: structure validator critiques as specific code locations + suggested fixes, not just prose. Modify pack_retry to include validator feedback as a first-class FailureSignal with category ValidatorRejection. Add structured fields: file, line_range, issue_type, suggested_fix. This creates tighter feedback loops and fewer iterations. Files: coordination/src/verifier/report.rs (add ValidatorFeedback type), coordination/src/context_packer/packer.rs (include in pack_retry), crates/swarm-agents/src/validator.rs (structured output), crates/swarm-agents/src/main.rs (wire feedback). Low effort, medium payoff.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:09.801827-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:09.801827-06:00"}
{"id":"beefcake-swarm-pid","title":"Expand verifier with Miri, proptest, cargo-deny gates","description":"STRONG CONSENSUS (3/4 models)\n\nThe verifier only runs fmt/clippy/check/test. Add risk-based verification gates:\n\nHigh-value additions:\n1. cargo miri test — UB detection for unsafe-heavy code (mandatory for any unsafe blocks)\n2. cargo deny check — security advisories, banned crates, license compliance\n3. cargo semver-checks — prevent accidental breaking API changes\n4. cargo udeps — detect unused dependencies introduced by agents\n5. nextest — faster test execution with better isolation + flaky detection\n6. Feature matrix: test with --no-default-features and key feature flags\n7. Doc tests / rustdoc lints for public API changes\n\nMake gates ADAPTIVE: select which extra gates to run based on diff risk profile:\n- Touches unsafe → require Miri\n- Changes Cargo.toml → require deny + udeps\n- Changes public API → require semver-checks\n- All changes → nextest with flaky detection\n\nFiles: coordination/src/verifier/pipeline.rs, coordination/src/verifier/ (new gate modules)","status":"open","priority":2,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:35:02.17173-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:35:02.17173-06:00"}
{"id":"beefcake-swarm-r93","title":"Wire beads_bridge to orchestrator main loop","description":"Connect beads_bridge.rs to the main orchestrator loop. List open issues, pick highest priority, update status to in_progress, close on completion. Use br CLI --json output for machine-readable parsing.","status":"closed","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:20.297648-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.372575-06:00","closed_at":"2026-02-11T16:02:59.372575-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-rb2","title":"Add worktree cleanup method for merge failure recovery","description":"WorktreeBridge::merge_and_remove() bails on merge conflict (line 140), leaving the worktree on disk and the swarm/\u003cid\u003e branch in the repo. The orchestrator exits with an error (line 306), creating zombie worktrees that block future attempts on the same issue (create() checks for existing worktree on line 74).\n\nFix: Add a remove_worktree(issue_id) method that force-removes the worktree and force-deletes the branch (git worktree remove --force + git branch -D). Use this in the orchestrator failure path so cleanup happens even when merge fails.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs, crates/swarm-agents/src/main.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:30.568197-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:11:30.568197-06:00"}
{"id":"beefcake-swarm-rzr","title":"Integrate Gastown for workspace isolation","description":"Wire up gastown CLI calls from swarm-agents orchestrator. Create worktrees per agent task on NFS (/cluster/shared/wt/\u003cissue_id\u003e). Prevent file conflicts for parallel agents. Commands: gastown create, gastown merge.","status":"closed","priority":1,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:16.884368-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:02:59.350146-06:00","closed_at":"2026-02-11T16:02:59.350146-06:00","close_reason":"Closed"}
{"id":"beefcake-swarm-tup","title":"Implement 2-agent loop MVP (orchestrator → implementer → verifier → validator)","description":"Core loop: orchestrator picks beads issue, creates gastown worktree, runs implementer (72B), deterministic verifier (fmt/clippy/test), blind validator (14B). If pass: merge+close. If fail: update notes, retry.","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:10.010034-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:10.010034-06:00","dependencies":[{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-r93","type":"blocks","created_at":"2026-02-11T15:32:56.348232-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-rzr","type":"blocks","created_at":"2026-02-11T15:32:56.434885-06:00","created_by":"TheFermiSea"},{"issue_id":"beefcake-swarm-tup","depends_on_id":"beefcake-swarm-8nm","type":"blocks","created_at":"2026-02-11T15:32:56.520579-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-ty0","title":"Use structured error fields in tracing macros","description":"Error logging uses string interpolation: error!('Failed to create worktree: {e}'). This embeds the error message in the format string, making it impossible for log aggregators (Loki, Datadog) to parse the error type separately from the message.\n\nFix: Use structured fields in tracing macros throughout main.rs and worktree_bridge.rs:\n- error!(error = %e, issue_id = %id, 'Failed to create worktree') — Display format\n- error!(error = ?e, issue_id = %id, 'Failed to create worktree') — Debug format (more detail)\n- warn!(iteration, feedback = %result.feedback, 'Validator FAILED')\n\nThis allows querying logs by error type, issue_id, or iteration number independently.\n\nFiles: crates/swarm-agents/src/main.rs, crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"open","priority":3,"issue_type":"task","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:14:31.658991-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:14:31.658991-06:00","dependencies":[{"issue_id":"beefcake-swarm-ty0","depends_on_id":"beefcake-swarm-ez1","type":"blocks","created_at":"2026-02-11T16:15:39.033017-06:00","created_by":"TheFermiSea"}]}
{"id":"beefcake-swarm-wpe","title":"Implement DSR prompt optimization (deferred)","description":"Dynamic System Reasoning for optimizing agent prompts based on success/failure feedback. Deferred from initial implementation. Track in backlog for future iteration.","status":"open","priority":4,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T15:32:41.835271-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T15:32:41.835271-06:00"}
{"id":"beefcake-swarm-xv9","title":"Handle detached HEAD in WorkPacketGenerator","description":"WorkPacketGenerator::git_branch() uses 'git rev-parse --abbrev-ref HEAD' which returns the literal string 'HEAD' when in detached HEAD state (common in CI, after checkout of a specific commit, or in freshly created worktrees before the first commit).\n\nThis means the WorkPacket.branch field becomes 'HEAD' which is misleading in the prompt sent to the LLM and may confuse the agent about which branch it's working on.\n\nFix: If git_branch() returns 'HEAD', fall back to:\n1. Check for CI env vars (CI_COMMIT_REF_NAME, GITHUB_HEAD_REF, BRANCH_NAME)\n2. Try 'git name-rev --name-only HEAD'\n3. Use 'detached@\u003cshort-sha\u003e' as a last resort\n\nFiles: coordination/src/work_packet/generator.rs\nFound by: G3-Pro deep review","status":"open","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:12:23.225461-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:12:23.225461-06:00"}
{"id":"beefcake-swarm-y2d","title":"Sanitize issue IDs to prevent path traversal","description":"WorktreeBridge::worktree_path() does base_dir.join(issue_id) with no validation. If issue_id contains path separators (e.g. ../../etc or ../../../tmp/evil), it could write worktrees outside the base directory.\n\nFix: Add validate_issue_id() that rejects any ID not matching [a-zA-Z0-9_-]. Call it in create(), merge_and_remove(), and worktree_path(). Beads IDs are alphanumeric-with-hyphens so this won't break real usage.\n\nFiles: crates/swarm-agents/src/worktree_bridge.rs\nFound by: G3-Pro deep review","status":"closed","priority":1,"issue_type":"bug","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:11:34.634992-06:00","created_by":"TheFermiSea","updated_at":"2026-02-12T11:14:25.71102-06:00","closed_at":"2026-02-12T11:14:25.71102-06:00","close_reason":"Fixed in PR #1 review commit a26ba46"}
{"id":"beefcake-swarm-yhx","title":"Build local SWE-bench-style evaluation harness","description":"Create a corpus of synthetic bead issues (or use real resolved ones) and measure swarm end-to-end: pass rate, iterations to green, tokens consumed, wallclock per phase, escalation frequency. This is how we decide between better retrieval vs bigger model vs more planning. Required before any prompt optimization (AdalFlow/TextGrad). Structure: (1) Issue corpus in .beads/ or test fixtures, (2) Runner that executes swarm loop per issue, (3) Metrics collector + summary report. GPT-5.2 specifically recommended this. Revisit AdalFlow/TextGrad after 50+ completed issues with logged data.","status":"open","priority":2,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:49:54.486409-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:49:54.486409-06:00"}
{"id":"beefcake-swarm-zg6","title":"Multi-proposal speculative execution for hard tasks","description":"UNANIMOUS CONSENSUS (4/4 models)\n\nFor hard/risky tasks, a single implementer often gets stuck in local minima. All 4 models propose spawning multiple implementations in parallel.\n\nDesign:\n1. Classify issue difficulty (simple vs hard) based on: error category history, file count, risk classification from Planner\n2. For hard tasks, spawn 2-3 Implementers in parallel with different strategies:\n   - Different temperature settings (0.2 conservative, 0.8 creative)\n   - Different system prompts ('minimal fix' vs 'refactor for clarity')\n   - Different model tiers (14B fast attempt + 72B deep attempt)\n3. Each produces a patch in its own worktree\n4. Run Verifier on all patches in parallel (CPU-bound, manageable)\n5. If multiple pass, Validator ranks and picks the best (most concise, least risk)\n6. If none pass, combine insights from all attempts for the retry context\n\nThis trades compute for success rate. G3-Pro: 'Parallel Speculative Decoding'. GPT-5.2: 'Selection via competition — turn merges into a market'.\n\nFiles: crates/swarm-agents/src/main.rs, crates/swarm-agents/src/worktree_bridge.rs (multi-worktree support)","status":"open","priority":1,"issue_type":"feature","owner":"squires.b@gmail.com","created_at":"2026-02-11T16:34:36.824715-06:00","created_by":"TheFermiSea","updated_at":"2026-02-11T16:34:36.824715-06:00","dependencies":[{"issue_id":"beefcake-swarm-zg6","depends_on_id":"beefcake-swarm-j4l","type":"blocks","created_at":"2026-02-11T16:35:50.86899-06:00","created_by":"TheFermiSea"}]}
